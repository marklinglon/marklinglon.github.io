{"meta":{"title":"汪茫人海","subtitle":"","description":"","author":"mark long","url":"https://marklinglon.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2024-02-01T08:17:24.098Z","updated":"2024-02-01T08:17:24.098Z","comments":false,"path":"/404.html","permalink":"https://marklinglon.github.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2024-02-01T08:17:24.104Z","updated":"2024-02-01T08:17:24.104Z","comments":false,"path":"about/index.html","permalink":"https://marklinglon.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2024-02-01T08:17:24.104Z","updated":"2024-02-01T08:17:24.104Z","comments":false,"path":"books/index.html","permalink":"https://marklinglon.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2024-02-01T08:17:24.104Z","updated":"2024-02-01T08:17:24.104Z","comments":false,"path":"categories/index.html","permalink":"https://marklinglon.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2024-02-01T08:17:24.122Z","updated":"2024-02-01T08:17:24.122Z","comments":true,"path":"links/index.html","permalink":"https://marklinglon.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2024-02-01T08:17:24.122Z","updated":"2024-02-01T08:17:24.122Z","comments":false,"path":"repository/index.html","permalink":"https://marklinglon.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2024-02-01T08:17:24.122Z","updated":"2024-02-01T08:17:24.122Z","comments":false,"path":"tags/index.html","permalink":"https://marklinglon.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"K个一组反转列表","slug":"算法/K个一组反转列表","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:54:30.238Z","comments":true,"path":"2024/02/01/算法/K个一组反转列表/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/K%E4%B8%AA%E4%B8%80%E7%BB%84%E5%8F%8D%E8%BD%AC%E5%88%97%E8%A1%A8/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package mainimport &quot;fmt&quot;type ListNode struct &#123; Val int Next *ListNode&#125;func reverseKGroup(head *ListNode, k int) *ListNode &#123; // 检查链表长度是否满足反转条件 count := 0 current := head for count &lt; k &#123; if current == nil &#123; return head &#125; current = current.Next count++ &#125; // 反转当前 K 个节点 prev := reverseList(head, current) // 递归处理下一组 K 个节点 head.Next = reverseKGroup(current, k) return prev&#125;func reverseList(head, tail *ListNode) *ListNode &#123; var prev, next *ListNode current := head for current != tail &#123; next = current.Next current.Next = prev prev = current current = next &#125; return prev&#125;func printList(head *ListNode) &#123; current := head for current != nil &#123; fmt.Printf(&quot;%d &quot;, current.Val) current = current.Next &#125; fmt.Println()&#125;func main() &#123; // 创建一个链表 head := &amp;ListNode&#123;Val: 1&#125; head.Next = &amp;ListNode&#123;Val: 2&#125; head.Next.Next = &amp;ListNode&#123;Val: 3&#125; head.Next.Next.Next = &amp;ListNode&#123;Val: 4&#125; head.Next.Next.Next.Next = &amp;ListNode&#123;Val: 5&#125; // 设定 K 的值 k := 2 // 反转链表每 K 个节点 result := reverseKGroup(head, k) // 输出结果 fmt.Print(&quot;反转后的链表: &quot;) printList(result)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"K个一组反转列表","slug":"K个一组反转列表","permalink":"https://marklinglon.github.io/tags/K%E4%B8%AA%E4%B8%80%E7%BB%84%E5%8F%8D%E8%BD%AC%E5%88%97%E8%A1%A8/"}]},{"title":"求最小数","slug":"算法/minInt","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:20:37.251Z","comments":true,"path":"2024/02/01/算法/minInt/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/minInt/","excerpt":"","text":"123456789101112131415161718func findMin(nums []int) int &#123; if len(nums) == 0 &#123; // 列表为空时返回一个合适的默认值，或者根据实际情况决定如何处理 return 0 &#125; // 初始化最小值为列表的第一个元素 min := nums[0] // 遍历列表，更新最小值 for _, num := range nums &#123; if num &lt; min &#123; min = num &#125; &#125; return min&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"最小数","slug":"最小数","permalink":"https://marklinglon.github.io/tags/%E6%9C%80%E5%B0%8F%E6%95%B0/"}]},{"title":"LRU缓存机制","slug":"算法/LRU缓存机制","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T10:00:50.331Z","comments":true,"path":"2024/02/01/算法/LRU缓存机制/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/LRU%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package mainimport &quot;fmt&quot;type LRUCache struct &#123; capacity int cache map[int]*Node head *Node tail *Node&#125;type Node struct &#123; key int value int prev *Node next *Node&#125;func Constructor(capacity int) LRUCache &#123; return LRUCache&#123; capacity: capacity, cache: make(map[int]*Node), head: nil, tail: nil, &#125;&#125;func (lru *LRUCache) get(key int) int &#123; if node, ok := lru.cache[key]; ok &#123; // 移动被访问的节点到头部 lru.moveToHead(node) return node.value &#125; return -1&#125;func (lru *LRUCache) put(key, value int) &#123; if node, ok := lru.cache[key]; ok &#123; // 更新节点值 node.value = value // 移动被访问的节点到头部 lru.moveToHead(node) &#125; else &#123; // 创建新节点 node := &amp;Node&#123;key: key, value: value&#125; lru.cache[key] = node // 缓存已满，淘汰最久未使用的节点 if len(lru.cache) &gt; lru.capacity &#123; lru.removeTail() &#125; // 将新节点添加到头部 lru.addToHead(node) &#125;&#125;func (lru *LRUCache) moveToHead(node *Node) &#123; if node != lru.head &#123; lru.removeNode(node) lru.addToHead(node) &#125;&#125;func (lru *LRUCache) removeNode(node *Node) &#123; if node.prev != nil &#123; node.prev.next = node.next &#125; else &#123; lru.head = node.next &#125; if node.next != nil &#123; node.next.prev = node.prev &#125; else &#123; lru.tail = node.prev &#125;&#125;func (lru *LRUCache) addToHead(node *Node) &#123; node.prev = nil node.next = lru.head if lru.head != nil &#123; lru.head.prev = node &#125; lru.head = node if lru.tail == nil &#123; lru.tail = node &#125;&#125;func (lru *LRUCache) removeTail() &#123; if lru.tail != nil &#123; delete(lru.cache, lru.tail.key) lru.removeNode(lru.tail) &#125;&#125;func main() &#123; // 创建容量为 2 的 LRU 缓存 lru := Constructor(2) // 插入键值对 lru.put(1, 1) lru.put(2, 2) // 查询键 1 fmt.Println(&quot;查询键 1 的结果:&quot;, lru.get(1)) // 输出 1 // 插入新的键值对 lru.put(3, 3) // 键 2 已经超出缓存容量，因此被淘汰 fmt.Println(&quot;查询键 2 的结果:&quot;, lru.get(2)) // 输出 -1 // 插入新的键值对 lru.put(4, 4) // 键 1 已经超出缓存容量，因此被淘汰 fmt.Println(&quot;查询键 1 的结果:&quot;, lru.get(1)) // 输出 -1 // 查询键 3 fmt.Println(&quot;查询键 3 的结果:&quot;, lru.get(3)) // 输出 3 // 查询键 4 fmt.Println(&quot;查询键 4 的结果:&quot;, lru.get(4)) // 输出 4&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"LRU缓存机制","slug":"LRU缓存机制","permalink":"https://marklinglon.github.io/tags/LRU%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/"}]},{"title":"搜索旋转排序数组","slug":"算法/xzList","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:34:16.104Z","comments":true,"path":"2024/02/01/算法/xzList/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/xzList/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package mainimport &quot;fmt&quot;type MyQueue struct &#123; inStack \\[\\]int outStack \\[\\]int&#125;func Constructor() MyQueue &#123; return MyQueue&#123;&#125;&#125;func (q *MyQueue) Enqueue(x int) &#123; q.inStack = append(q.inStack, x)&#125;func (q *MyQueue) Dequeue() int &#123; if len(q.outStack) == 0 &#123; q.transfer() &#125; if len(q.outStack) == 0 &#123; // 队列为空，返回一个合适的默认值，或者根据实际情况决定如何处理 return 0 &#125; val := q.outStack\\[len(q.outStack)-1\\] q.outStack = q.outStack\\[:len(q.outStack)-1\\] return val&#125;func (q *MyQueue) transfer() &#123; for len(q.inStack) &gt; 0 &#123; q.outStack = append(q.outStack, q.inStack\\[len(q.inStack)-1\\]) q.inStack = q.inStack\\[:len(q.inStack)-1\\] &#125;&#125;func main() &#123; queue := Constructor() queue.Enqueue(1) queue.Enqueue(2) queue.Enqueue(3) fmt.Println(queue.Dequeue()) // 输出：1 fmt.Println(queue.Dequeue()) // 输出：2 queue.Enqueue(4) fmt.Println(queue.Dequeue()) // 输出：3 fmt.Println(queue.Dequeue()) // 输出：4&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"旋转排序数组","slug":"旋转排序数组","permalink":"https://marklinglon.github.io/tags/%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84/"}]},{"title":"用栈实现队列","slug":"算法/zhanQueue","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:29:22.790Z","comments":true,"path":"2024/02/01/算法/zhanQueue/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/zhanQueue/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package mainimport &quot;fmt&quot;type MyQueue struct &#123; inStack []int outStack []int&#125;func Constructor() MyQueue &#123; return MyQueue&#123;&#125;&#125;func (q *MyQueue) Enqueue(x int) &#123; q.inStack = append(q.inStack, x)&#125;func (q *MyQueue) Dequeue() int &#123; if len(q.outStack) == 0 &#123; q.transfer() &#125; if len(q.outStack) == 0 &#123; // 队列为空，返回一个合适的默认值，或者根据实际情况决定如何处理 return 0 &#125; val := q.outStack[len(q.outStack)-1] q.outStack = q.outStack[:len(q.outStack)-1] return val&#125;func (q *MyQueue) transfer() &#123; for len(q.inStack) &gt; 0 &#123; q.outStack = append(q.outStack, q.inStack[len(q.inStack)-1]) q.inStack = q.inStack[:len(q.inStack)-1] &#125;&#125;func main() &#123; queue := Constructor() queue.Enqueue(1) queue.Enqueue(2) queue.Enqueue(3) fmt.Println(queue.Dequeue()) // 输出：1 fmt.Println(queue.Dequeue()) // 输出：2 queue.Enqueue(4) fmt.Println(queue.Dequeue()) // 输出：3 fmt.Println(queue.Dequeue()) // 输出：4&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"栈 队列","slug":"栈-队列","permalink":"https://marklinglon.github.io/tags/%E6%A0%88-%E9%98%9F%E5%88%97/"}]},{"title":"不含AAA或BBB的字符串","slug":"算法/不含AAA或BBB的字符串","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:48:43.450Z","comments":true,"path":"2024/02/01/算法/不含AAA或BBB的字符串/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E4%B8%8D%E5%90%ABAAA%E6%88%96BBB%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2/","excerpt":"","text":"1234567891011121314151617181920212223242526package mainimport &quot;fmt&quot;func generateString() string &#123; result := &quot;&quot; countA, countB := 0, 0 for countA+countB &lt; 7 &#123; // 控制字符串长度，这里选择了 7，你可以根据实际情况调整 if countA &lt; 2 || (countA &gt;= 2 &amp;&amp; countB &lt; 1) &#123; result += &quot;A&quot; countA++ &#125; else &#123; result += &quot;B&quot; countB++ &#125; &#125; return result&#125;func main() &#123; str := generateString() fmt.Println(&quot;生成的字符串:&quot;, str)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"不含AAA或BBB的字符串","slug":"不含AAA或BBB的字符串","permalink":"https://marklinglon.github.io/tags/%E4%B8%8D%E5%90%ABAAA%E6%88%96BBB%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"二叉树的最近公共祖先","slug":"算法/二叉树的最近公共祖先","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:36:49.346Z","comments":true,"path":"2024/02/01/算法/二叉树的最近公共祖先/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E8%BF%91%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package mainimport &quot;fmt&quot;type TreeNode struct &#123; Val int Left *TreeNode Right *TreeNode&#125;func lowestCommonAncestor(root, p, q *TreeNode) *TreeNode &#123; if root == nil &#123; return nil &#125; // 如果当前节点是 p 或 q，则它本身就是最近公共祖先 if root == p || root == q &#123; return root &#125; // 在左子树中递归寻找最近公共祖先 left := lowestCommonAncestor(root.Left, p, q) // 在右子树中递归寻找最近公共祖先 right := lowestCommonAncestor(root.Right, p, q) // 如果左右子树分别找到 p 和 q，则当前节点是最近公共祖先 if left != nil &amp;&amp; right != nil &#123; return root &#125; // 如果左子树找到 p 或 q，则返回左子树的结果 if left != nil &#123; return left &#125; // 如果右子树找到 p 或 q，则返回右子树的结果 return right&#125;func main() &#123; // 创建一个二叉树 root := &amp;TreeNode&#123;Val: 3&#125; root.Left = &amp;TreeNode&#123;Val: 5&#125; root.Right = &amp;TreeNode&#123;Val: 1&#125; root.Left.Left = &amp;TreeNode&#123;Val: 6&#125; root.Left.Right = &amp;TreeNode&#123;Val: 2&#125; root.Right.Left = &amp;TreeNode&#123;Val: 0&#125; root.Right.Right = &amp;TreeNode&#123;Val: 8&#125; root.Left.Right.Left = &amp;TreeNode&#123;Val: 7&#125; root.Left.Right.Right = &amp;TreeNode&#123;Val: 4&#125; // 定义两个节点 p := root.Left q := root.Left.Right.Right // 找到最近公共祖先 result := lowestCommonAncestor(root, p, q) // 输出最近公共祖先的值 fmt.Printf(&quot;节点 %d 和节点 %d 的最近公共祖先是节点 %d\\n&quot;, p.Val, q.Val, result.Val)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树的最近公共祖先","slug":"二叉树的最近公共祖先","permalink":"https://marklinglon.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E8%BF%91%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88/"}]},{"title":"合并区间","slug":"算法/合并区间","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:55:53.632Z","comments":true,"path":"2024/02/01/算法/合并区间/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/","excerpt":"","text":"合并区间是一个常见的算法问题，目标是将重叠的区间合并成一个或多个不重叠的区间。以下是一个用 Golang 实现的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package mainimport ( &quot;fmt&quot; &quot;sort&quot;)type Interval struct &#123; Start int End int&#125;func merge(intervals []Interval) []Interval &#123; if len(intervals) &lt;= 1 &#123; return intervals &#125; // 将区间按照起始位置进行排序 sort.Slice(intervals, func(i, j int) bool &#123; return intervals[i].Start &lt; intervals[j].Start &#125;) merged := []Interval&#123;intervals[0]&#125; for i := 1; i &lt; len(intervals); i++ &#123; current := intervals[i] lastMerged := merged[len(merged)-1] // 判断当前区间与上一个合并后的区间是否有重叠 if current.Start &lt;= lastMerged.End &#123; // 有重叠，更新合并后的区间的结束位置 merged[len(merged)-1].End = max(lastMerged.End, current.End) &#125; else &#123; // 无重叠，直接加入合并后的结果 merged = append(merged, current) &#125; &#125; return merged&#125;func max(a, b int) int &#123; if a &gt; b &#123; return a &#125; return b&#125;func main() &#123; // 创建一组区间 intervals := []Interval&#123; &#123;1, 3&#125;, &#123;2, 6&#125;, &#123;8, 10&#125;, &#123;15, 18&#125;, &#125; // 合并区间 result := merge(intervals) // 输出结果 fmt.Println(&quot;合并后的区间:&quot;, result)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"合并区间","slug":"合并区间","permalink":"https://marklinglon.github.io/tags/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/"}]},{"title":"四数组相加II","slug":"算法/四数组相加II","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:39:12.750Z","comments":true,"path":"2024/02/01/算法/四数组相加II/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E5%9B%9B%E6%95%B0%E7%BB%84%E7%9B%B8%E5%8A%A0II/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637package mainimport &quot;fmt&quot;func fourSumCount(A []int, B []int, C []int, D []int) int &#123; sumCount := make(map[int]int) // 统计A和B数组中元素的和的组合 for _, a := range A &#123; for _, b := range B &#123; sumCount[a+b]++ &#125; &#125; result := 0 // 遍历C和D数组，查找和的相反数在sumCount中的数量 for _, c := range C &#123; for _, d := range D &#123; result += sumCount[-(c + d)] &#125; &#125; return result&#125;func main() &#123; A := []int&#123;1, 2&#125; B := []int&#123;-2, -1&#125; C := []int&#123;-1, 2&#125; D := []int&#123;0, 2&#125; count := fourSumCount(A, B, C, D) fmt.Printf(&quot;满足条件的组合数量是：%d\\n&quot;, count)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"四数组相加II","slug":"四数组相加II","permalink":"https://marklinglon.github.io/tags/%E5%9B%9B%E6%95%B0%E7%BB%84%E7%9B%B8%E5%8A%A0II/"}]},{"title":"子集","slug":"算法/子集","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:57:59.724Z","comments":true,"path":"2024/02/01/算法/子集/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E5%AD%90%E9%9B%86/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233package mainimport &quot;fmt&quot;func subsets(nums []int) [][]int &#123; result := [][]int&#123;&#125; backtrack(nums, []int&#123;&#125;, &amp;result, 0) return result&#125;func backtrack(nums, current []int, result *[][]int, start int) &#123; temp := make([]int, len(current)) copy(temp, current) *result = append(*result, temp) for i := start; i &lt; len(nums); i++ &#123; current = append(current, nums[i]) backtrack(nums, current, result, i+1) current = current[:len(current)-1] &#125;&#125;func main() &#123; // 给定集合 nums := []int&#123;1, 2, 3&#125; // 求子集 result := subsets(nums) // 输出结果 fmt.Println(&quot;所有可能的子集:&quot;, result)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"子集","slug":"子集","permalink":"https://marklinglon.github.io/tags/%E5%AD%90%E9%9B%86/"}]},{"title":"字符串解码","slug":"算法/字符串解码","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T10:03:18.548Z","comments":true,"path":"2024/02/01/算法/字符串解码/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%A7%A3%E7%A0%81/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package mainimport ( &quot;fmt&quot; &quot;strings&quot;)func decodeString(s string) string &#123; stack := []string&#123;&#125; currentNum := 0 currentStr := &quot;&quot; for _, char := range s &#123; if char &gt;= &#x27;0&#x27; &amp;&amp; char &lt;= &#x27;9&#x27; &#123; // 当前字符是数字，更新当前数字 currentNum = currentNum*10 + int(char-&#x27;0&#x27;) &#125; else if char == &#x27;[&#x27; &#123; // 当前字符是左括号，将当前数字和字符串入栈，并重置 stack = append(stack, currentStr, fmt.Sprint(currentNum)) currentStr = &quot;&quot; currentNum = 0 &#125; else if char == &#x27;]&#x27; &#123; // 当前字符是右括号，出栈数字和字符串，进行解码 num, _ := fmt.Sprint(stack[len(stack)-1]) stack = stack[:len(stack)-1] prevStr := stack[len(stack)-1] stack = stack[:len(stack)-1] repeatedStr := strings.Repeat(currentStr, numToInt(num)) currentStr = prevStr + repeatedStr &#125; else &#123; // 当前字符是字母，追加到当前字符串 currentStr += string(char) &#125; &#125; return currentStr&#125;func numToInt(numStr string) int &#123; num, _ := fmt.Sprint(numStr) result := 0 for _, digit := range num &#123; result = result*10 + int(digit-&#x27;0&#x27;) &#125; return result&#125;func main() &#123; // 示例字符串 encodedStr := &quot;3[a2[bc]]&quot; // 解码字符串 decodedStr := decodeString(encodedStr) // 输出结果 fmt.Printf(&quot;解码后的字符串: %s\\n&quot;, decodedStr)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"字符串解码","slug":"字符串解码","permalink":"https://marklinglon.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%A7%A3%E7%A0%81/"}]},{"title":"二叉树的锯齿型层次遍历","slug":"算法/二叉树的锯齿型层次遍历","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:45:29.354Z","comments":true,"path":"2024/02/01/算法/二叉树的锯齿型层次遍历/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%94%AF%E9%BD%BF%E5%9E%8B%E5%B1%82%E6%AC%A1%E9%81%8D%E5%8E%86/","excerpt":"","text":"二叉树的锯齿形层次遍历是指从左到右和从右到左交替进行的层次遍历。在锯齿形层次遍历中，奇数层从左到右遍历，偶数层从右到左遍历。以下是一个用 Golang 实现的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package mainimport &quot;fmt&quot;func sum(nums []int) int &#123; result := 0 for _, num := range nums &#123; result += num &#125; return result&#125;func main() &#123; numbers := []int&#123;1, 2, 3, 4, 5&#125; total := sum(numbers) fmt.Printf(&quot;数组 %v 的和是 %d\\n&quot;, numbers, total)&#125;package mainimport ( &quot;fmt&quot;)type TreeNode struct &#123; Val int Left *TreeNode Right *TreeNode&#125;func zigzagLevelOrder(root *TreeNode) [][]int &#123; if root == nil &#123; return nil &#125; result := [][]int&#123;&#125; queue := []*TreeNode&#123;root&#125; level := 0 for len(queue) &gt; 0 &#123; levelSize := len(queue) currentLevel := make([]int, levelSize) for i := 0; i &lt; levelSize; i++ &#123; node := queue[0] queue = queue[1:] // 根据当前层的奇偶性判断插入顺序 if level%2 == 0 &#123; currentLevel[i] = node.Val &#125; else &#123; currentLevel[levelSize-i-1] = node.Val &#125; // 将左右子节点加入队列 if node.Left != nil &#123; queue = append(queue, node.Left) &#125; if node.Right != nil &#123; queue = append(queue, node.Right) &#125; &#125; result = append(result, currentLevel) level++ &#125; return result&#125;func main() &#123; // 创建一个二叉树 root := &amp;TreeNode&#123;Val: 3&#125; root.Left = &amp;TreeNode&#123;Val: 9&#125; root.Right = &amp;TreeNode&#123;Val: 20&#125; root.Right.Left = &amp;TreeNode&#123;Val: 15&#125; root.Right.Right = &amp;TreeNode&#123;Val: 7&#125; // 进行锯齿形层次遍历 result := zigzagLevelOrder(root) // 输出结果 fmt.Println(result)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"二叉树的锯齿型层次遍历","slug":"二叉树的锯齿型层次遍历","permalink":"https://marklinglon.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%94%AF%E9%BD%BF%E5%9E%8B%E5%B1%82%E6%AC%A1%E9%81%8D%E5%8E%86/"}]},{"title":"数组中的第K个最大元素","slug":"算法/数组中的第K个最大元素","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T10:01:49.308Z","comments":true,"path":"2024/02/01/算法/数组中的第K个最大元素/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E7%AC%ACK%E4%B8%AA%E6%9C%80%E5%A4%A7%E5%85%83%E7%B4%A0/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package mainimport &quot;fmt&quot;type LRUCache struct &#123; capacity int cache map[int]*Node head *Node tail *Node&#125;type Node struct &#123; key int value int prev *Node next *Node&#125;func Constructor(capacity int) LRUCache &#123; return LRUCache&#123; capacity: capacity, cache: make(map[int]*Node), head: nil, tail: nil, &#125;&#125;func (lru *LRUCache) get(key int) int &#123; if node, ok := lru.cache[key]; ok &#123; // 移动被访问的节点到头部 lru.moveToHead(node) return node.value &#125; return -1&#125;func (lru *LRUCache) put(key, value int) &#123; if node, ok := lru.cache[key]; ok &#123; // 更新节点值 node.value = value // 移动被访问的节点到头部 lru.moveToHead(node) &#125; else &#123; // 创建新节点 node := &amp;Node&#123;key: key, value: value&#125; lru.cache[key] = node // 缓存已满，淘汰最久未使用的节点 if len(lru.cache) &gt; lru.capacity &#123; lru.removeTail() &#125; // 将新节点添加到头部 lru.addToHead(node) &#125;&#125;func (lru *LRUCache) moveToHead(node *Node) &#123; if node != lru.head &#123; lru.removeNode(node) lru.addToHead(node) &#125;&#125;func (lru *LRUCache) removeNode(node *Node) &#123; if node.prev != nil &#123; node.prev.next = node.next &#125; else &#123; lru.head = node.next &#125; if node.next != nil &#123; node.next.prev = node.prev &#125; else &#123; lru.tail = node.prev &#125;&#125;func (lru *LRUCache) addToHead(node *Node) &#123; node.prev = nil node.next = lru.head if lru.head != nil &#123; lru.head.prev = node &#125; lru.head = node if lru.tail == nil &#123; lru.tail = node &#125;&#125;func (lru *LRUCache) removeTail() &#123; if lru.tail != nil &#123; delete(lru.cache, lru.tail.key) lru.removeNode(lru.tail) &#125;&#125;func main() &#123; // 创建容量为 2 的 LRU 缓存 lru := Constructor(2) // 插入键值对 lru.put(1, 1) lru.put(2, 2) // 查询键 1 fmt.Println(&quot;查询键 1 的结果:&quot;, lru.get(1)) // 输出 1 // 插入新的键值对 lru.put(3, 3) // 键 2 已经超出缓存容量，因此被淘汰 fmt.Println(&quot;查询键 2 的结果:&quot;, lru.get(2)) // 输出 -1 // 插入新的键值对 lru.put(4, 4) // 键 1 已经超出缓存容量，因此被淘汰 fmt.Println(&quot;查询键 1 的结果:&quot;, lru.get(1)) // 输出 -1 // 查询键 3 fmt.Println(&quot;查询键 3 的结果:&quot;, lru.get(3)) // 输出 3 // 查询键 4 fmt.Println(&quot;查询键 4 的结果:&quot;, lru.get(4)) // 输出 4&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组中的第K个最大元素","slug":"数组中的第K个最大元素","permalink":"https://marklinglon.github.io/tags/%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E7%AC%ACK%E4%B8%AA%E6%9C%80%E5%A4%A7%E5%85%83%E7%B4%A0/"}]},{"title":"对称二叉树","slug":"算法/对称二叉树","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:47:58.131Z","comments":true,"path":"2024/02/01/算法/对称二叉树/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport &quot;fmt&quot;type TreeNode struct &#123; Val int Left *TreeNode Right *TreeNode&#125;func isSymmetric(root *TreeNode) bool &#123; if root == nil &#123; return true &#125; return isMirror(root.Left, root.Right)&#125;func isMirror(left, right *TreeNode) bool &#123; if left == nil &amp;&amp; right == nil &#123; return true &#125; if left == nil || right == nil &#123; return false &#125; return left.Val == right.Val &amp;&amp; isMirror(left.Left, right.Right) &amp;&amp; isMirror(left.Right, right.Left)&#125;func main() &#123; // 创建一个对称二叉树 root := &amp;TreeNode&#123;Val: 1&#125; root.Left = &amp;TreeNode&#123;Val: 2&#125; root.Right = &amp;TreeNode&#123;Val: 2&#125; root.Left.Left = &amp;TreeNode&#123;Val: 3&#125; root.Left.Right = &amp;TreeNode&#123;Val: 4&#125; root.Right.Left = &amp;TreeNode&#123;Val: 4&#125; root.Right.Right = &amp;TreeNode&#123;Val: 3&#125; // 判断二叉树是否对称 result := isSymmetric(root) // 输出结果 fmt.Println(result)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"对称二叉树","slug":"对称二叉树","permalink":"https://marklinglon.github.io/tags/%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91/"}]},{"title":"数组求和","slug":"算法/数组求和","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:34:01.610Z","comments":true,"path":"2024/02/01/算法/数组求和/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84%E6%B1%82%E5%92%8C/","excerpt":"","text":"123456789101112131415161718package mainimport &quot;fmt&quot;func sum(nums []int) int &#123; result := 0 for _, num := range nums &#123; result += num &#125; return result&#125;func main() &#123; numbers := []int&#123;1, 2, 3, 4, 5&#125; total := sum(numbers) fmt.Printf(&quot;数组 %v 的和是 %d\\n&quot;, numbers, total)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"求和","slug":"求和","permalink":"https://marklinglon.github.io/tags/%E6%B1%82%E5%92%8C/"}]},{"title":"整数反转","slug":"算法/整数反转","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:50:24.852Z","comments":true,"path":"2024/02/01/算法/整数反转/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E6%95%B4%E6%95%B0%E5%8F%8D%E8%BD%AC/","excerpt":"","text":"123456789101112131415161718192021222324252627282930package mainimport &quot;fmt&quot;func reverse(x int) int &#123; result := 0 for x != 0 &#123; digit := x % 10 x /= 10 // 检查溢出情况 if result &gt; (1&lt;&lt;31-1)/10 || (result == (1&lt;&lt;31-1)/10 &amp;&amp; digit &gt; 7) &#123; return 0 &#125; if result &lt; (-1&lt;&lt;31)/10 || (result == (-1&lt;&lt;31)/10 &amp;&amp; digit &lt; -8) &#123; return 0 &#125; result = result*10 + digit &#125; return result&#125;func main() &#123; num := 12345 reversed := reverse(num) fmt.Printf(&quot;整数 %d 的反转结果是 %d\\n&quot;, num, reversed)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"整数反转","slug":"整数反转","permalink":"https://marklinglon.github.io/tags/%E6%95%B4%E6%95%B0%E5%8F%8D%E8%BD%AC/"}]},{"title":"根到叶子结点的数字之和","slug":"算法/根到叶子结点的数字之和","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:59:20.427Z","comments":true,"path":"2024/02/01/算法/根到叶子结点的数字之和/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E6%A0%B9%E5%88%B0%E5%8F%B6%E5%AD%90%E7%BB%93%E7%82%B9%E7%9A%84%E6%95%B0%E5%AD%97%E4%B9%8B%E5%92%8C/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport &quot;fmt&quot;type TreeNode struct &#123; Val int Left *TreeNode Right *TreeNode&#125;func sumNumbers(root *TreeNode) int &#123; return dfs(root, 0)&#125;func dfs(node *TreeNode, currentSum int) int &#123; if node == nil &#123; return 0 &#125; // 计算当前路径上的数字之和 currentSum = currentSum*10 + node.Val // 如果是叶子结点，返回当前路径的数字之和 if node.Left == nil &amp;&amp; node.Right == nil &#123; return currentSum &#125; // 递归计算左右子树的数字之和 return dfs(node.Left, currentSum) + dfs(node.Right, currentSum)&#125;func main() &#123; // 创建一个二叉树 root := &amp;TreeNode&#123;Val: 1&#125; root.Left = &amp;TreeNode&#123;Val: 2&#125; root.Right = &amp;TreeNode&#123;Val: 3&#125; root.Left.Left = &amp;TreeNode&#123;Val: 4&#125; root.Left.Right = &amp;TreeNode&#123;Val: 5&#125; // 计算根到叶子结点的数字之和 result := sumNumbers(root) // 输出结果 fmt.Printf(&quot;根到叶子结点的数字之和是：%d\\n&quot;, result)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"根到叶子结点的数字之和","slug":"根到叶子结点的数字之和","permalink":"https://marklinglon.github.io/tags/%E6%A0%B9%E5%88%B0%E5%8F%B6%E5%AD%90%E7%BB%93%E7%82%B9%E7%9A%84%E6%95%B0%E5%AD%97%E4%B9%8B%E5%92%8C/"}]},{"title":"组合数组","slug":"算法/组合数组","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:35:43.785Z","comments":true,"path":"2024/02/01/算法/组合数组/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E7%BB%84%E5%90%88%E6%95%B0%E7%BB%84/","excerpt":"","text":"12345678910package mainimport &quot;fmt&quot;func main() &#123; array1 := []int&#123;1, 2, 3&#125; array2 := []int&#123;4, 5, 6&#125; combinedArray := append(array1, array2...) fmt.Println(combinedArray)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数组 组合","slug":"数组-组合","permalink":"https://marklinglon.github.io/tags/%E6%95%B0%E7%BB%84-%E7%BB%84%E5%90%88/"}]},{"title":"最大正方形","slug":"算法/最大正方形","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:43:37.055Z","comments":true,"path":"2024/02/01/算法/最大正方形/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E6%9C%80%E5%A4%A7%E6%AD%A3%E6%96%B9%E5%BD%A2/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package mainimport &quot;fmt&quot;func maximalSquare(matrix [][]byte) int &#123; if len(matrix) == 0 || len(matrix[0]) == 0 &#123; return 0 &#125; rows, cols := len(matrix), len(matrix[0]) dp := make([][]int, rows) maxSide := 0 for i := range dp &#123; dp[i] = make([]int, cols) for j := range dp[i] &#123; dp[i][j] = int(matrix[i][j] - &#x27;0&#x27;) if dp[i][j] == 1 &#123; maxSide = 1 // 初始化最大边长为1 &#125; &#125; &#125; for i := 1; i &lt; rows; i++ &#123; for j := 1; j &lt; cols; j++ &#123; if dp[i][j] == 1 &#123; dp[i][j] = min(dp[i-1][j-1], min(dp[i-1][j], dp[i][j-1])) + 1 maxSide = max(maxSide, dp[i][j]) &#125; &#125; &#125; return maxSide * maxSide&#125;func min(a, b int) int &#123; if a &lt; b &#123; return a &#125; return b&#125;func max(a, b int) int &#123; if a &gt; b &#123; return a &#125; return b&#125;func main() &#123; matrix := [][]byte&#123; &#123;&#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;&#125;, &#123;&#x27;1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;&#125;, &#123;&#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;, &#x27;1&#x27;&#125;, &#123;&#x27;1&#x27;, &#x27;0&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;0&#x27;&#125;, &#125; area := maximalSquare(matrix) fmt.Printf(&quot;最大正方形的面积是：%d\\n&quot;, area)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"最大正方形","slug":"最大正方形","permalink":"https://marklinglon.github.io/tags/%E6%9C%80%E5%A4%A7%E6%AD%A3%E6%96%B9%E5%BD%A2/"}]},{"title":"路径总和","slug":"算法/路径总和","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:52:07.775Z","comments":true,"path":"2024/02/01/算法/路径总和/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E8%B7%AF%E5%BE%84%E6%80%BB%E5%92%8C/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport &quot;fmt&quot;type TreeNode struct &#123; Val int Left *TreeNode Right *TreeNode&#125;func hasPathSum(root *TreeNode, targetSum int) bool &#123; if root == nil &#123; return false &#125; // 如果当前节点是叶子节点，判断路径上的和是否等于目标和 if root.Left == nil &amp;&amp; root.Right == nil &#123; return targetSum == root.Val &#125; // 递归判断左右子树是否存在路径满足条件 return hasPathSum(root.Left, targetSum-root.Val) || hasPathSum(root.Right, targetSum-root.Val)&#125;func main() &#123; // 创建一个二叉树 root := &amp;TreeNode&#123;Val: 5&#125; root.Left = &amp;TreeNode&#123;Val: 4&#125; root.Right = &amp;TreeNode&#123;Val: 8&#125; root.Left.Left = &amp;TreeNode&#123;Val: 11&#125; root.Left.Left.Left = &amp;TreeNode&#123;Val: 7&#125; root.Left.Left.Right = &amp;TreeNode&#123;Val: 2&#125; root.Right.Left = &amp;TreeNode&#123;Val: 13&#125; root.Right.Right = &amp;TreeNode&#123;Val: 4&#125; root.Right.Right.Right = &amp;TreeNode&#123;Val: 1&#125; // 设定目标和 targetSum := 22 // 判断是否存在路径满足条件 result := hasPathSum(root, targetSum) // 输出结果 fmt.Printf(&quot;是否存在路径和为 %d 的路径: %v\\n&quot;, targetSum, result)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"路径总和","slug":"路径总和","permalink":"https://marklinglon.github.io/tags/%E8%B7%AF%E5%BE%84%E6%80%BB%E5%92%8C/"}]},{"title":"罗马数字转整数","slug":"算法/罗马数字转整数","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T09:53:16.091Z","comments":true,"path":"2024/02/01/算法/罗马数字转整数/","link":"","permalink":"https://marklinglon.github.io/2024/02/01/%E7%AE%97%E6%B3%95/%E7%BD%97%E9%A9%AC%E6%95%B0%E5%AD%97%E8%BD%AC%E6%95%B4%E6%95%B0/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940package mainimport &quot;fmt&quot;func romanToInt(s string) int &#123; romanMap := map[byte]int&#123; &#x27;I&#x27;: 1, &#x27;V&#x27;: 5, &#x27;X&#x27;: 10, &#x27;L&#x27;: 50, &#x27;C&#x27;: 100, &#x27;D&#x27;: 500, &#x27;M&#x27;: 1000, &#125; result := 0 prevValue := 0 for i := len(s) - 1; i &gt;= 0; i-- &#123; currentValue := romanMap[s[i]] if currentValue &lt; prevValue &#123; result -= currentValue &#125; else &#123; result += currentValue &#125; prevValue = currentValue &#125; return result&#125;func main() &#123; romanNumeral := &quot;IX&quot; result := romanToInt(romanNumeral) fmt.Printf(&quot;罗马数字 %s 转换为整数是 %d\\n&quot;, romanNumeral, result)&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"罗马数字转整数","slug":"罗马数字转整数","permalink":"https://marklinglon.github.io/tags/%E7%BD%97%E9%A9%AC%E6%95%B0%E5%AD%97%E8%BD%AC%E6%95%B4%E6%95%B0/"}]},{"title":"Redis常见问题","slug":"中间件/redis面试题","date":"2024-01-20T16:00:00.000Z","updated":"2024-02-01T09:24:48.471Z","comments":true,"path":"2024/01/21/中间件/redis面试题/","link":"","permalink":"https://marklinglon.github.io/2024/01/21/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"","text":"Redis是什么？ Redis（Remote Dictionary Server）是一个使用 C 语言编写的，高性能非关系型的键值对数据库。与传统数据库不同的是，Redis 的数据是存在内存中的，所以读写速度非常快，被广泛应用于缓存方向。Redis可以将数据写入磁盘中，保证了数据的安全不丢失，而且Redis的操作是原子性的。 Redis优缺点？ 优点： 基于内存操作，内存读写速度快。 支持多种数据类型，包括String、Hash、List、Set、ZSet等。 支持持久化。Redis支持RDB和AOF两种持久化机制，持久化功能可以有效地避免数据丢失问题。 支持事务。Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。 支持主从复制。主节点会自动将数据同步到从节点，可以进行读写分离。 Redis命令的处理是单线程的。Redis6.0引入了多线程，需要注意的是，多线程用于处理网络数据的读写和协议解析，Redis命令执行还是单线程的。 缺点： 对结构化查询的支持比较差。 数据库容量受到物理内存的限制，不适合用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的操作。 Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。 Redis为什么这么快？ 基于内存：Redis是使用内存存储，没有磁盘IO上的开销。数据存在内存中，读写速度快。 IO多路复用模型：Redis 采用 IO 多路复用技术。Redis 使用单线程来轮询描述符，将数据库的操作都转换成了事件，不在网络I/O上浪费过多的时间。 高效的数据结构：Redis 每种数据类型底层都做了优化，目的就是为了追求更快的速度。 本文已经收录到Github仓库，该仓库包含计算机基础、Java基础、多线程、JVM、数据库、Redis、Spring、Mybatis、SpringMVC、SpringBoot、分布式、微服务、设计模式、架构、校招社招分享等核心知识点，欢迎star~ Github地址：https://github.com/Tyson0314/Java-learning 如果访问不了Github，可以访问gitee地址。 gitee地址：https://gitee.com/tysondai/Java-learning 既然Redis那么快，为什么不用它做主数据库，只用它做缓存？ 虽然Redis非常快，但它也有一些局限性，不能完全替代主数据库。有以下原因： 事务处理：Redis只支持简单的事务处理，对于复杂的事务无能为力，比如跨多个键的事务处理。 数据持久化：Redis是内存数据库，数据存储在内存中，如果服务器崩溃或断电，数据可能丢失。虽然Redis提供了数据持久化机制，但有一些限制。 数据处理：Redis只支持一些简单的数据结构，比如字符串、列表、哈希表等。如果需要处理复杂的数据结构，比如关系型数据库中的表，那么Redis可能不是一个好的选择。 数据安全：Redis没有提供像主数据库那样的安全机制，比如用户认证、访问控制等等。 因此，虽然Redis非常快，但它还有一些限制，不能完全替代主数据库。所以，使用Redis作为缓存是一种很好的方式，可以提高应用程序的性能，并减少数据库的负载。 讲讲Redis的线程模型？ Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。 文件事件处理器使用I/O多路复用（multiplexing）程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。 当被监听的套接字准备好执行连接accept、read、write、close等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。 虽然文件事件处理器以单线程方式运行， 但通过使用 I/O 多路复用程序来监听多个套接字， 文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 Redis 内部单线程设计的简单性。 Redis应用场景有哪些？ 缓存热点数据，缓解数据库的压力。 利用 Redis 原子性的自增操作，可以实现计数器的功能，比如统计用户点赞数、用户访问数等。 分布式锁。在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。 简单的消息队列，可以使用Redis自身的发布/订阅模式或者List来实现简单的消息队列，实现异步操作。 限速器，可用于限制某个用户访问某个接口的频率，比如秒杀场景用于防止用户快速点击带来不必要的压力。 好友关系，利用集合的一些命令，比如交集、并集、差集等，实现共同好友、共同爱好之类的功能。 Memcached和Redis的区别？ MemCached 数据结构单一，仅用来缓存数据，而 Redis 支持多种数据类型。 MemCached 不支持数据持久化，重启后数据会消失。Redis 支持数据持久化。 Redis 提供主从同步机制和 cluster 集群部署能力，能够提供高可用服务。Memcached 没有提供原生的集群模式，需要依靠客户端实现往集群中分片写入数据。 Redis 的速度比 Memcached 快很多。 Redis 使用单线程的多路 IO 复用模型，Memcached使用多线程的非阻塞 IO 模型。（Redis6.0引入了多线程IO，用来处理网络数据的读写和协议解析，但是命令的执行仍然是单线程） value 值大小不同：Redis 最大可以达到 512M；memcache 只有 1mb。 为什么要用 Redis 而不用 map/guava 做缓存? 使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。 使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。 Redis 数据类型有哪些？ 基本数据类型： 1、String：最常用的一种数据类型，String类型的值可以是字符串、数字或者二进制，但值最大不能超过512MB。 2、Hash：Hash 是一个键值对集合。 3、Set：无序去重的集合。Set 提供了交集、并集等方法，对于实现共同好友、共同关注等功能特别方便。 4、List：有序可重复的集合，底层是依赖双向链表实现的。 5、SortedSet：有序Set。内部维护了一个score的参数来实现。适用于排行榜和带权重的消息队列等场景。 特殊的数据类型： 1、Bitmap：位图，可以认为是一个以位为单位数组，数组中的每个单元只能存0或者1，数组的下标在 Bitmap 中叫做偏移量。Bitmap的长度与集合中元素个数无关，而是与基数的上限有关。 2、Hyperloglog。HyperLogLog 是用来做基数统计的算法，其优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。典型的使用场景是统计独立访客。 3、Geospatial ：主要用于存储地理位置信息，并对存储的信息进行操作，适用场景如定位、附近的人等。 SortedSet和List异同点？ 相同点： 都是有序的； 都可以获得某个范围内的元素。 不同点： 列表基于链表实现，获取两端元素速度快，访问中间元素速度慢； 有序集合基于散列表和跳跃表实现，访问中间元素时间复杂度是OlogN； 列表不能简单的调整某个元素的位置，有序列表可以（更改元素的分数）； 有序集合更耗内存。 Redis的内存用完了会怎样？ 如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回）。 也可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。 Redis如何做内存优化？ 可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面。 keys命令存在的问题？ redis的单线程的。keys指令会导致线程阻塞一段时间，直到执行完毕，服务才能恢复。scan采用渐进式遍历的方式来解决keys命令可能带来的阻塞问题，每次scan命令的时间复杂度是O(1)，但是要真正实现keys的功能，需要执行多次scan。 scan的缺点：在scan的过程中如果有键的变化（增加、删除、修改），遍历过程可能会有以下问题：新增的键可能没有遍历到，遍历出了重复的键等情况，也就是说scan并不能保证完整的遍历出来所有的键。 Redis事务 事务的原理是将一个事务范围内的若干命令发送给Redis，然后再让Redis依次执行这些命令。 事务的生命周期： 使用MULTI开启一个事务 在开启事务的时候，每次操作的命令将会被插入到一个队列中，同时这个命令并不会被真的执行 EXEC命令进行提交事务 一个事务范围内某个命令出错不会影响其他命令的执行，不保证原子性： 123456789101112127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set a 1QUEUED127.0.0.1:6379&gt; set b 1 2QUEUED127.0.0.1:6379&gt; set c 3QUEUED127.0.0.1:6379&gt; exec1) OK2) (error) ERR syntax error3) OK WATCH命令 WATCH命令可以监控一个或多个键，一旦其中有一个键被修改，之后的事务就不会执行（类似于乐观锁）。执行EXEC命令之后，就会自动取消监控。 1234567891011121314127.0.0.1:6379&gt; watch nameOK127.0.0.1:6379&gt; set name 1OK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set name 2QUEUED127.0.0.1:6379&gt; set gender 1QUEUED127.0.0.1:6379&gt; exec(nil)127.0.0.1:6379&gt; get gender(nil) 比如上面的代码中： watch name开启了对name这个key的监控,修改name的值,开启事务a,在事务a中设置了name和gender的值,使用EXEC命令进提交事务,使用命令get gender发现不存在，即事务a没有执行,使用UNWATCH可以取消WATCH命令对key的监控，所有监控锁将会被取消。 Redis事务支持隔离性吗？ Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。 Redis事务保证原子性吗，支持回滚吗？ Redis单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。 持久化机制 持久化就是把内存的数据写到磁盘中，防止服务宕机导致内存数据丢失。 Redis支持两种方式的持久化，一种是RDB的方式，一种是AOF的方式。前者会根据指定的规则定时将内存中的数据存储在硬盘上，而后者在每次执行完命令后将命令记录下来。一般将两者结合使用。 RDB方式 RDB是 Redis 默认的持久化方案。RDB持久化时会将内存中的数据写入到磁盘中，在指定目录下生成一个dump.rdb文件。Redis 重启会加载dump.rdb文件恢复数据。 bgsave是主流的触发 RDB 持久化的方式，执行过程如下： 执行BGSAVE命令 Redis 父进程判断当前是否存在正在执行的子进程，如果存在，BGSAVE命令直接返回。 父进程执行fork操作创建子进程，fork操作过程中父进程会阻塞。 父进程fork完成后，父进程继续接收并处理客户端的请求，而子进程开始将内存中的数据写进硬盘的临时文件； 当子进程写完所有数据后会用该临时文件替换旧的 RDB 文件。 Redis启动时会读取RDB快照文件，将数据从硬盘载入内存。通过 RDB 方式的持久化，一旦Redis异常退出，就会丢失最近一次持久化以后更改的数据。 触发 RDB 持久化的方式： 手动触发： 用户执行SAVE或BGSAVE命令。SAVE命令执行快照的过程会阻塞所有客户端的请求，应避免在生产环境使用此命令。BGSAVE命令可以在后台异步进行快照操作，快照的同时服务器还可以继续响应客户端的请求，因此需要手动执行快照时推荐使用BGSAVE命令。 被动触发： 根据配置规则进行自动快照，如SAVE 100 10，100秒内至少有10个键被修改则进行快照。 如果从节点执行全量复制操作，主节点会自动执行BGSAVE生成 RDB 文件并发送给从节点。 默认情况下执行shutdown命令时，如果没有开启 AOF 持久化功能则自动执行·BGSAVE·。 优点： Redis 加载 RDB 恢复数据远远快于 AOF 的方式。 使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 Redis 的高性能。 缺点： RDB方式数据无法做到实时持久化。因为BGSAVE每次运行都要执行fork操作创建子进程，属于重量级操作，频繁执行成本比较高。 RDB 文件使用特定二进制格式保存，Redis 版本升级过程中有多个格式的 RDB 版本，存在老版本 Redis 无法兼容新版 RDB 格式的问题。 AOF方式 AOF（append only file）持久化：以独立日志的方式记录每次写命令，Redis重启时会重新执行AOF文件中的命令达到恢复数据的目的。AOF的主要作用是解决了数据持久化的实时性，AOF 是Redis持久化的主流方式。 默认情况下Redis没有开启AOF方式的持久化，可以通过appendonly参数启用：appendonly yes。开启AOF方式持久化后每执行一条写命令，Redis就会将该命令写进aof_buf缓冲区，AOF缓冲区根据对应的策略向硬盘做同步操作。 默认情况下系统每30秒会执行一次同步操作。为了防止缓冲区数据丢失，可以在Redis写入AOF文件后主动要求系统将缓冲区数据同步到硬盘上。可以通过appendfsync参数设置同步的时机。 appendfsync always //每次写入aof文件都会执行同步，最安全最慢，不建议配置 appendfsync everysec //既保证性能也保证安全，建议配置 appendfsync no //由操作系统决定何时进行同步操作 接下来看一下 AOF 持久化执行流程： 所有的写入命令会追加到 AOP 缓冲区中。 AOF 缓冲区根据对应的策略向硬盘同步。 随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩文件体积的目的。AOF文件重写是把Redis进程内的数据转化为写命令同步到新AOF文件的过程。 当 Redis 服务器重启时，可以加载 AOF 文件进行数据恢复。 优点： AOF可以更好的保护数据不丢失，可以配置 AOF 每秒执行一次fsync操作，如果Redis进程挂掉，最多丢失1秒的数据。 AOF以append-only的模式写入，所以没有磁盘寻址的开销，写入性能非常高。 缺点： 对于同一份文件AOF文件比RDB数据快照要大。 数据恢复比较慢。 RDB和AOF如何选择？ 通常来说，应该同时使用两种持久化方案，以保证数据安全。 如果数据不敏感，且可以从其他地方重新生成，可以关闭持久化。 如果数据比较重要，且能够承受几分钟的数据丢失，比如缓存等，只需要使用RDB即可。 如果是用做内存数据，要使用Redis的持久化，建议是RDB和AOF都开启。 如果只用AOF，优先使用everysec的配置选择，因为它在可靠性和性能之间取了一个平衡。 当RDB与AOF两种方式都开启时，Redis会优先使用AOF恢复数据，因为AOF保存的文件比RDB文件更完整。 Redis有哪些部署方案？ 单机版：单机部署，单机redis能够承载的 QPS 大概就在上万到几万不等。这种部署方式很少使用。存在的问题：1、内存容量有限 2、处理能力有限 3、无法高可用。 主从模式：一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。master 节点挂掉后，需要手动指定新的 master，可用性不高，基本不用。 哨兵模式：主从复制存在不能自动故障转移、达不到高可用的问题。哨兵模式解决了这些问题。通过哨兵机制可以自动切换主从节点。master 节点挂掉后，哨兵进程会主动选举新的 master，可用性高，但是每个节点存储的数据是一样的，浪费内存空间。数据量不是很多，集群规模不是很大，需要自动容错容灾的时候使用。 Redis cluster：服务端分片技术，3.0版本开始正式提供。Redis Cluster并没有使用一致性hash，而是采用slot(槽)的概念，一共分成16384个槽。将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确的节点上执行。主要是针对海量数据+高并发+高可用的场景，如果是海量数据，如果你的数据量很大，那么建议就用Redis cluster，所有主节点的容量总和就是Redis cluster可缓存的数据容量。 主从架构 单机的 redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。 Redis的复制功能是支持多个数据库之间的数据同步。主数据库可以进行读写操作，当主数据库的数据发生变化时会自动将数据同步到从数据库。从数据库一般是只读的，它会接收主数据库同步过来的数据。一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库。 主从复制的原理？ 当启动一个从节点时，它会发送一个 PSYNC 命令给主节点； 如果是从节点初次连接到主节点，那么会触发一次全量复制。此时主节点会启动一个后台线程，开始生成一份 RDB 快照文件； 同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， 主节点会将RDB文件发送给从节点，从节点会先将RDB文件写入本地磁盘，然后再从本地磁盘加载到内存中； 接着主节点会将内存中缓存的写命令发送到从节点，从节点同步这些数据； 如果从节点跟主节点之间网络出现故障，连接断开了，会自动重连，连接之后主节点仅会将部分缺失的数据同步给从节点。 哨兵Sentinel 主从复制存在不能自动故障转移、达不到高可用的问题。哨兵模式解决了这些问题。通过哨兵机制可以自动切换主从节点。 客户端连接Redis的时候，先连接哨兵，哨兵会告诉客户端Redis主节点的地址，然后客户端连接上Redis并进行后续的操作。当主节点宕机的时候，哨兵监测到主节点宕机，会重新推选出某个表现良好的从节点成为新的主节点，然后通过发布订阅模式通知其他的从服务器，让它们切换主机。 每个Sentinel以每秒钟一次的频率向它所知道的Master，Slave以及其他 Sentinel实例发送一个 PING命令。 如果一个实例距离最后一次有效回复 PING 命令的时间超过指定值， 则这个实例会被 Sentine 标记为主观下线。 如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel要以每秒一次的频率确认Master是否真正进入主观下线状态。 当有足够数量的 Sentinel（大于等于配置文件指定值）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线 。若没有足够数量的 Sentinel同意 Master 已经下线， Master 的客观下线状态就会被解除。 若 Master重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。 哨兵节点会选举出哨兵 leader，负责故障转移的工作。 哨兵 leader 会推选出某个表现良好的从节点成为新的主节点，然后通知其他从节点更新主节点信息。 Redis cluster 哨兵模式解决了主从复制不能自动故障转移、达不到高可用的问题，但还是存在主节点的写能力、容量受限于单机配置的问题。而cluster模式实现了Redis的分布式存储，每个节点存储不同的内容，解决主节点的写能力、容量受限于单机配置的问题。 Redis cluster集群节点最小配置6个节点以上（3主3从），其中主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。 Redis cluster采用虚拟槽分区，所有的键根据哈希函数映射到0～16383个整数槽内，每个节点负责维护一部分槽以及槽所映射的键值数据。 工作原理： 通过哈希的方式，将数据分片，每个节点均分存储一定哈希槽(哈希值)区间的数据，默认分配了16384 个槽位 每份数据分片会存储在多个互为主从的多节点上 数据写入先写主节点，再同步到从节点(支持配置为阻塞同步) 同一分片多个节点间的数据不保持一致性 读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点 扩容时时需要需要把旧节点的数据迁移一部分到新节点 在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。 16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，gossip 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。 优点： 无中心架构，支持动态扩容； 数据按照slot存储分布在多个节点，节点间数据共享，可动态调整数据分布； 高可用性。部分节点不可用时，集群仍可用。集群模式能够实现自动故障转移（failover），节点之间通过gossip协议交换状态信息，用投票机制完成Slave到Master的角色转换。 缺点： 不支持批量操作（pipeline）。 数据通过异步复制，不保证数据的强一致性。 事务操作支持有限，只支持多key在同一节点上的事务操作，当多个key分布于不同的节点上时无法使用事务功能。 key作为数据分区的最小粒度，不能将一个很大的键值对象如hash、list等映射到不同的节点。 不支持多数据库空间，单机下的Redis可以支持到16个数据库，集群模式下只能使用1个数据库空间。 只能使用0号数据库。 哈希分区算法有哪些？ 节点取余分区。使用特定的数据，如Redis的键或用户ID，对节点数量N取余：hash（key）%N计算出哈希值，用来决定数据映射到哪一个节点上。 优点是简单性。扩容时通常采用翻倍扩容，避免数据映射全部被打乱导致全量迁移的情况。 一致性哈希分区。为系统中每个节点分配一个token，范围一般在0~232，这些token构成一个哈希环。数据读写执行节点查找操作时，先根据key计算hash值，然后顺时针找到第一个大于等于该哈希值的token节点。 这种方式相比节点取余最大的好处在于加入和删除节点只影响哈希环中相邻的节点，对其他节点无影响。 虚拟槽分区，所有的键根据哈希函数映射到0~16383整数槽内，计算公式：slot=CRC16（key）&amp;16383。每一个节点负责维护一部分槽以及槽所映射的键值数据。Redis Cluser采用虚拟槽分区算法。 过期键的删除策略？ 1、被动删除。在访问key时，如果发现key已经过期，那么会将key删除。 2、主动删除。定时清理key，每次清理会依次遍历所有DB，从db随机取出20个key，如果过期就删除，如果其中有5个key过期，那么就继续对这个db进行清理，否则开始清理下一个db。 3、内存不够时清理。Redis有最大内存的限制，通过maxmemory参数可以设置最大内存，当使用的内存超过了设置的最大内存，就要进行内存释放， 在进行内存释放的时候，会按照配置的淘汰策略清理内存。 内存淘汰策略有哪些？ 当Redis的内存超过最大允许的内存之后，Redis 会触发内存淘汰策略，删除一些不常用的数据，以保证Redis服务器正常运行。 Redisv4.0前提供 6 种数据淘汰策略： volatile-lru：LRU（Least Recently Used），最近使用。利用LRU算法移除设置了过期时间的key allkeys-lru：当内存不足以容纳新写入数据时，从数据集中移除最近最少使用的key volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集中任意选择数据淘汰 allkeys-random：从数据集中任意选择数据淘汰 no-eviction：禁止删除数据，当内存不足以容纳新写入数据时，新写入操作会报错 Redisv4.0后增加以下两种： volatile-lfu：LFU，Least Frequently Used，最少使用，从已设置过期时间的数据集中挑选最不经常使用的数据淘汰。 allkeys-lfu：当内存不足以容纳新写入数据时，从数据集中移除最不经常使用的key。 内存淘汰策略可以通过配置文件来修改，相应的配置项是maxmemory-policy，默认配置是noeviction。 如何保证缓存与数据库双写时的数据一致性？ 1、先删除缓存再更新数据库 进行更新操作时，先删除缓存，然后更新数据库，后续的请求再次读取时，会从数据库读取后再将新数据更新到缓存。 存在的问题：删除缓存数据之后，更新数据库完成之前，这个时间段内如果有新的读请求过来，就会从数据库读取旧数据重新写到缓存中，再次造成不一致，并且后续读的都是旧数据。 2、先更新数据库再删除缓存 进行更新操作时，先更新MySQL，成功之后，删除缓存，后续读取请求时再将新数据回写缓存。 存在的问题：更新MySQL和删除缓存这段时间内，请求读取的还是缓存的旧数据，不过等数据库更新完成，就会恢复一致，影响相对比较小。 3、异步更新缓存 数据库的更新操作完成后不直接操作缓存，而是把这个操作命令封装成消息扔到消息队列中，然后由Redis自己去消费更新数据，消息队列可以保证数据操作顺序一致性，确保缓存系统的数据正常。 以上几个方案都不完美，需要根据业务需求，评估哪种方案影响较小，然后选择相应的方案。 缓存常见问题 缓存穿透 缓存穿透是指查询一个不存在的数据，由于缓存是不命中时被动写的，如果从DB查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到DB去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了。 怎么解决？ 缓存空值，不会查数据库。 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，查询不存在的数据会被这个bitmap拦截掉，从而避免了对DB的查询压力。 布隆过滤器的原理：当一个元素被加入集合时，通过K个哈希函数将这个元素映射成一个位数组中的K个点，把它们置为1。查询时，将元素通过哈希函数映射之后会得到k个点，如果这些点有任何一个0，则被检元素一定不在，直接返回；如果都是1，则查询元素很可能存在，就会去查询Redis和数据库。 布隆过滤器一般用于在大数据量的集合中判定某元素是否存在。 缓存雪崩 缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重挂掉。 解决方法： 在原有的失效时间基础上增加一个随机值，使得过期时间分散一些。这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 加锁排队可以起到缓冲的作用，防止大量的请求同时操作数据库，但它的缺点是增加了系统的响应时间，降低了系统的吞吐量，牺牲了一部分用户体验。当缓存未查询到时，对要请求的 key 进行加锁，只允许一个线程去数据库中查，其他线程等候排队。 设置二级缓存。二级缓存指的是除了 Redis 本身的缓存，再设置一层缓存，当 Redis 失效之后，先去查询二级缓存。例如可以设置一个本地缓存，在 Redis 缓存失效的时候先去查询本地缓存而非查询数据库。 缓存击穿 缓存击穿：大量的请求同时查询一个 key 时，此时这个 key 正好失效了，就会导致大量的请求都落到数据库。缓存击穿是查询缓存中失效的 key，而缓存穿透是查询不存在的 key。 解决方法： 1、加互斥锁。在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程拿不到锁就阻塞等着，等到第一个线程将数据写入缓存后，直接走缓存。可以使用Redis分布式锁实现，代码如下： 1234567891011121314151617public String get(String key) &#123; String value = redis.get(key); if (value == null) &#123; //缓存值过期 String unique_key = systemId + &quot;:&quot; + key; //设置30s的超时 if (redis.set(unique_key, 1, &#x27;NX&#x27;, &#x27;PX&#x27;, 30000) == 1) &#123; //设置成功 value = db.get(key); redis.set(key, value, expire_secs); redis.del(unique_key); &#125; else &#123; //其他线程已经到数据库取值并回写到缓存了，可以重试获取缓存值 sleep(50); get(key); //重试 &#125; &#125; else &#123; return value; &#125;&#125; 2、热点数据不过期。直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存。这种方式适用于比较极端的场景，例如流量特别特别大的场景，使用时需要考虑业务能接受数据不一致的时间，还有就是异常情况的处理，保证缓存可以定时刷新。 缓存预热 缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！ 解决方案： 直接写个缓存刷新页面，上线时手工操作一下； 数据量不大，可以在项目启动的时候自动进行加载； 定时刷新缓存； 缓存降级 当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。 缓存降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。 在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案： 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级； 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警； 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级； 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。 服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。 Redis 怎么实现消息队列？ 使用list类型保存数据信息，rpush生产消息，lpop消费消息，当lpop没有消息时，可以sleep一段时间，然后再检查有没有信息，如果不想sleep的话，可以使用blpop, 在没有信息的时候，会一直阻塞，直到信息的到来。 BLPOP queue 0 //0表示不限制等待时间 BLPOP和LPOP命令相似，唯一的区别就是当列表没有元素时BLPOP命令会一直阻塞连接，直到有新元素加入。 redis可以通过pub/sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。 PUBLISH channel1 hi SUBSCRIBE channel1 UNSUBSCRIBE channel1 //退订通过SUBSCRIBE命令订阅的频道。 PSUBSCRIBE channel?* 按照规则订阅。 PUNSUBSCRIBE channel?* 退订通过PSUBSCRIBE命令按照某种规则订阅的频道。其中订阅规则要进行严格的字符串匹配，PUNSUBSCRIBE *无法退订channel?*规则。 Redis 怎么实现延时队列 使用sortedset，拿时间戳作为score，消息内容作为key，调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。 pipeline的作用？ redis客户端执行一条命令分4个过程： 发送命令、命令排队、命令执行、返回结果。使用pipeline可以批量请求，批量返回结果，执行速度比逐条执行要快。 使用pipeline组装的命令个数不能太多，不然数据量过大，增加客户端的等待时间，还可能造成网络阻塞，可以将大量命令的拆分多个小的pipeline命令完成。 原生批命令（mset和mget）与pipeline对比： 原生批命令是原子性，pipeline是非原子性。pipeline命令中途异常退出，之前执行成功的命令不会回滚。 原生批命令只有一个命令，但pipeline支持多命令。 LUA脚本 Redis 通过 LUA 脚本创建具有原子性的命令： 当lua脚本命令正在运行的时候，不会有其他脚本或 Redis 命令被执行，实现组合命令的原子操作。 在Redis中执行Lua脚本有两种方法：eval和evalsha。eval命令使用内置的 Lua 解释器，对 Lua 脚本进行求值。 //第一个参数是lua脚本，第二个参数是键名参数个数，剩下的是键名参数和附加参数 eval “return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}” 2 key1 key2 first second “key1” “key2” “first” “second” lua脚本作用 1、Lua脚本在Redis中是原子执行的，执行过程中间不会插入其他命令。 2、Lua脚本可以将多条命令一次性打包，有效地减少网络开销。 应用场景 举例：限制接口访问频率。 在Redis维护一个接口访问次数的键值对，key是接口名称，value是访问次数。每次访问接口时，会执行以下操作： 通过aop拦截接口的请求，对接口请求进行计数，每次进来一个请求，相应的接口访问次数count加1，存入redis。 如果是第一次请求，则会设置count=1，并设置过期时间。因为这里set()和expire()组合操作不是原子操作，所以引入lua脚本，实现原子操作，避免并发访问问题。 如果给定时间范围内超过最大访问次数，则会抛出异常。 12345678910111213141516private String buildLuaScript() &#123; return &quot;local c&quot; + &quot;\\nc = redis.call(&#x27;get&#x27;,KEYS[1])&quot; + &quot;\\nif c and tonumber(c) &gt; tonumber(ARGV[1]) then&quot; + &quot;\\nreturn c;&quot; + &quot;\\nend&quot; + &quot;\\nc = redis.call(&#x27;incr&#x27;,KEYS[1])&quot; + &quot;\\nif tonumber(c) == 1 then&quot; + &quot;\\nredis.call(&#x27;expire&#x27;,KEYS[1],ARGV[2])&quot; + &quot;\\nend&quot; + &quot;\\nreturn c;&quot;;&#125;String luaScript = buildLuaScript();RedisScript&lt;Number&gt; redisScript = new DefaultRedisScript&lt;&gt;(luaScript, Number.class);Number count = redisTemplate.execute(redisScript, keys, limit.count(), limit.period()); PS：这种接口限流的实现方式比较简单，问题也比较多，一般不会使用，接口限流用的比较多的是令牌桶算法和漏桶算法。 什么是RedLock？ Redis 官方站提出了一种权威的基于 Redis 实现分布式锁的方式名叫 Redlock，此种方式比原先的单节点的方法更安全。它可以保证以下特性： 安全特性：互斥访问，即永远只有一个 client 能拿到锁 避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client 挂掉了 容错性：只要大部分 Redis 节点存活就可以正常提供服务 Redis大key怎么处理？ 通常我们会将含有较大数据或含有大量成员、列表数的Key称之为大Key。 以下是对各个数据类型大key的描述： value是STRING类型，它的值超过5MB value是ZSET、Hash、List、Set等集合类型时，它的成员数量超过1w个 上述的定义并不绝对，主要是根据value的成员数量和大小来确定，根据业务场景确定标准。 怎么处理： 当vaule是string时，可以使用序列化、压缩算法将key的大小控制在合理范围内，但是序列化和反序列化都会带来更多时间上的消耗。或者将key进行拆分，一个大key分为不同的部分，记录每个部分的key，使用multiget等操作实现事务读取。 当value是list/set等集合类型时，根据预估的数据规模来进行分片，不同的元素计算后分到不同的片。 Redis常见性能问题和解决方案？ Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。 如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。 尽量避免在压力较大的主库上增加从库 Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 为了Master的稳定性，主从复制不要用图状结构，用单向链表结构更稳定，即主从关系为：Master&lt;–Slave1&lt;–Slave2&lt;–Slave3…，这样的结构也方便解决单点故障问题，实现Slave对Master的替换，也即，如果Master挂了，可以立马启用Slave1做Master，其他不变。 说说为什么Redis过期了为什么内存没释放？ 第一种情况，可能是覆盖之前的key，导致key过期时间发生了改变。 当一个key在Redis中已经存在了，但是由于一些误操作使得key过期时间发生了改变，从而导致这个key在应该过期的时间内并没有过期，从而造成内存的占用。 第二种情况是，Redis过期key的处理策略导致内存没释放。 一般Redis对过期key的处理策略有两种：惰性删除和定时删除。 先说惰性删除的情况 当一个key已经确定设置了xx秒过期同时中间也没有修改它，xx秒之后它确实已经过期了，但是惰性删除的策略它并不会马上删除这个key，而是当再次读写这个key时它才会去检查是否过期，如果过期了就会删除这个key。也就是说，惰性删除策略下，就算key过期了，也不会立刻释放内容，要等到下一次读写这个key才会删除key。 而定时删除会在一定时间内主动淘汰一部分已经过期的数据，默认的时间是每100ms过期一次。因为定时删除策略每次只会淘汰一部分过期key，而不是所有的过期key，如果redis中数据比较多的话要是一次性全量删除对服务器的压力比较大，每一次只挑一批进行删除，所以很可能出现部分已经过期的key并没有及时的被清理掉，从而导致内存没有即时被释放。 Redis突然变慢，有哪些原因？ 存在bigkey。如果Redis实例中存储了 bigkey，那么在淘汰删除 bigkey 释放内存时，也会耗时比较久。应该避免存储 bigkey，降低释放内存的耗时。 如果Redis 实例设置了内存上限 maxmemory，有可能导致 Redis 变慢。当 Redis 内存达到 maxmemory 后，每次写入新的数据之前，Redis 必须先从实例中踢出一部分数据，让整个实例的内存维持在 maxmemory 之下，然后才能把新数据写进来。 开启了内存大页。当 Redis 在执行后台 RDB 和 AOF rewrite 时，采用 fork 子进程的方式来处理。但主进程 fork 子进程后，此时的主进程依旧是可以接收写请求的，而进来的写请求，会采用 Copy On Write（写时复制）的方式操作内存数据。 什么是写时复制？ 这样做的好处是，父进程有任何写操作，并不会影响子进程的数据持久化。 不过，主进程在拷贝内存数据时，会涉及到新内存的申请，如果此时操作系统开启了内存大页，那么在此期间，客户端即便只修改 10B 的数据，Redis 在申请内存时也会以 2MB 为单位向操作系统申请，申请内存的耗时变长，进而导致每个写请求的延迟增加，影响到 Redis 性能。 解决方案就是关闭内存大页机制。 使用了Swap。操作系统为了缓解内存不足对应用程序的影响，允许把一部分内存中的数据换到磁盘上，以达到应用程序对内存使用的缓冲，这些内存数据被换到磁盘上的区域，就是 Swap。当内存中的数据被换到磁盘上后，Redis 再访问这些数据时，就需要从磁盘上读取，访问磁盘的速度要比访问内存慢几百倍。尤其是针对 Redis 这种对性能要求极高、性能极其敏感的数据库来说，这个操作延时是无法接受的。解决方案就是增加机器的内存，让 Redis 有足够的内存可以使用。或者整理内存空间，释放出足够的内存供 Redis 使用 网络带宽过载。网络带宽过载的情况下，服务器在 TCP 层和网络层就会出现数据包发送延迟、丢包等情况。Redis 的高性能，除了操作内存之外，就在于网络 IO 了，如果网络 IO 存在瓶颈，那么也会严重影响 Redis 的性能。解决方案：1、及时确认占满网络带宽 Redis 实例，如果属于正常的业务访问，那就需要及时扩容或迁移实例了，避免因为这个实例流量过大，影响这个机器的其他实例。2、运维层面，需要对 Redis 机器的各项指标增加监控，包括网络流量，在网络流量达到一定阈值时提前报警，及时确认和扩容。 频繁短连接。频繁的短连接会导致 Redis 大量时间耗费在连接的建立和释放上，TCP 的三次握手和四次挥手同样也会增加访问延迟。应用应该使用长连接操作 Redis，避免频繁的短连接。 为什么 Redis 集群的最大槽数是 16384 个？ Redis Cluster 采用数据分片机制，定义了 16384个 Slot槽位，集群中的每个Redis 实例负责维护一部分槽以及槽所映射的键值数据。 Redis每个节点之间会定期发送ping/pong消息（心跳包包含了其他节点的数据），用于交换数据信息。 Redis集群的节点会按照以下规则发ping消息： (1)每秒会随机选取5个节点，找出最久没有通信的节点发送ping消息 (2)每100毫秒都会扫描本地节点列表，如果发现节点最近一次接受pong消息的时间大于cluster-node-timeout/2 则立刻发送ping消息 心跳包的消息头里面有个myslots的char数组，是一个bitmap，每一个位代表一个槽，如果该位为1，表示这个槽是属于这个节点的。 接下来，解答为什么 Redis 集群的最大槽数是 16384 个，而不是65536 个。 1、如果采用 16384 个插槽，那么心跳包的消息头占用空间 2KB （16384/8）；如果采用 65536 个插槽，那么心跳包的消息头占用空间 8KB (65536/8)。可见采用 65536 个插槽，发送心跳信息的消息头达8k，比较浪费带宽。 2、一般情况下一个Redis集群不会有超过1000个master节点，太多可能导致网络拥堵。 3、哈希槽是通过一张bitmap的形式来保存的，在传输过程中，会对bitmap进行压缩。bitmap的填充率越低，压缩率越高。其中bitmap 填充率 = slots / N (N表示节点数)。所以，插槽数越低， 填充率会降低，压缩率会提高。","categories":[{"name":"mianshiti","slug":"mianshiti","permalink":"https://marklinglon.github.io/categories/mianshiti/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://marklinglon.github.io/tags/redis/"}]},{"title":"jumpserver问题处理","slug":"工具/jumpserver","date":"2023-05-20T16:00:00.000Z","updated":"2024-02-01T09:23:28.798Z","comments":true,"path":"2023/05/21/工具/jumpserver/","link":"","permalink":"https://marklinglon.github.io/2023/05/21/%E5%B7%A5%E5%85%B7/jumpserver/","excerpt":"","text":"登陆提示密码过期 WARNING: Your password has expired. You must change your password now and login again! Changing password for user . Current password: 处理 管理员登陆jumpserver 修改用户密码 用securecrt登陆该用户，发现问题依旧 chage -l 用户名 // 查看用户密码过期时间 修改宿主机的密码策略 vim /etc/login.def PASS_MAX_DAYS 99999 ansible TestCvm -m shell -a “chage -M -1 username” // 设置某个用户的密码过期时间永不过期","categories":[{"name":"工具","slug":"工具","permalink":"https://marklinglon.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"jumpserer","slug":"jumpserer","permalink":"https://marklinglon.github.io/tags/jumpserer/"}]},{"title":"wechat gpt","slug":"工具/wechatgpt","date":"2023-05-20T16:00:00.000Z","updated":"2024-02-01T09:25:11.153Z","comments":true,"path":"2023/05/21/工具/wechatgpt/","link":"","permalink":"https://marklinglon.github.io/2023/05/21/%E5%B7%A5%E5%85%B7/wechatgpt/","excerpt":"","text":"下载 git clone https://github.com/869413421/wechatbot.git 进入项目目录 cd wechatbot 创建配置文件 123456cat &gt;&gt; config.json &lt;&lt;EOF&#123; &quot;api_key&quot;: &quot;your gpt api key&quot;, &quot;auto_pass&quot;: true&#125;EOF 启动项目 go run main.go 换账号登陆 rm -f storage.json go run main.go","categories":[{"name":"工具","slug":"工具","permalink":"https://marklinglon.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"gpt","slug":"gpt","permalink":"https://marklinglon.github.io/tags/gpt/"}]},{"title":"K8s文章分享","slug":"k8s/share","date":"2022-03-20T16:00:00.000Z","updated":"2024-02-01T10:04:24.187Z","comments":true,"path":"2022/03/21/k8s/share/","link":"","permalink":"https://marklinglon.github.io/2022/03/21/k8s/share/","excerpt":"","text":"分享链接 minikube minikube部署k8s集群 https://mp.weixin.qq.com/s/xHpmEZM7-kjWar_z4ADWXg kubeadmin kubeadmin部署k8s集群 https://mp.weixin.qq.com/s/WvIg6uszw9QIkIT05cYcgQ kind kind部署k8s集群 https://mp.weixin.qq.com/s/YG5dNGH-T75HsXmLOQh5AA rke rke部署k8s集群 https://mp.weixin.qq.com/s/A4CJei7plYE9PJ2W2RRAOw ceph k8s私有云分布式存储搭建 https://mp.weixin.qq.com/s/CdLioTzU4oWI688lqYKXUQ ceph-k8s k8s对接ceph https://mp.weixin.qq.com/s/lHEC83E1iKy7ojUadWNU6w k8s k8s自建集群 https://mp.weixin.qq.com/s/473vdYANq2E_R51Lh94-9Q k8s-multus-CNI K8s Multus CNI的部署与工作原理 https://mp.weixin.qq.com/s/oSxR3ex2mnLk0qJdD6WGJg k8s-cni k8s自建cni https://mp.weixin.qq.com/s/K6ynL_9nSTLCTy0_2xCobg k8s-operator operator最佳实践 http://blazehu.com/2022/04/10/cloudnative/kubebuilder/ argocd/flux Argo CD 与 Flux CD — Kubernetes 集群的正确 GitOps 工具 https://mp.weixin.qq.com/s/RVmt6INalZdsGAxwRX_Veg prometheus 云原生大型分布式监控系统(一): 大规模场景下 Prometheus 的优化手段 https://mp.weixin.qq.com/s/Pd1ip05z8zxVKaAPmuKNnw prometheus 云原生大型分布式监控系统(二): Thanos 架构详解 https://mp.weixin.qq.com/s/oGyrJ4QiQ9KSYLuMSJnYYQ prometheus 云原生大型分布式监控系统(三): Thanos 部署与实践 https://mp.weixin.qq.com/s/sinLteFNKGNI1-vBv28xGg prometheus 云原生大型分布式监控系统(四): Kvass+Thanos 监控超大规模容器集群 https://mp.weixin.qq.com/s/gjW21wium2ZxVSBKE-hHtQ kubecm Kubeconfig文件自动合并-实现K8S多集群切换 https://mp.weixin.qq.com/s/2f2cAWMd03AdOt2QJEapPA kluster-capacity K8s 集群容量 - kluster capacity https://mp.weixin.qq.com/s/6VEut9TR8Y0Y6VuurjAarw k8s-scheduler K8s 调度系统由浅入深 https://mp.weixin.qq.com/s/fizeaWjrtZD-EwuVQIt3ag Karmada K8s 多集群管理 – Karmada 调度器 https://mp.weixin.qq.com/s/OdRMAPxV1lPGhsKivSYH_Q mimirtool prometheus瘦身工具 https://mp.weixin.qq.com/s/z23gYsLIkvbBePg-FUMJXA Kubernetes Descheduler k8s二次调度 https://mp.weixin.qq.com/s/kfqyRgagvHWeOiTprFqH9w","categories":[{"name":"K8s","slug":"K8s","permalink":"https://marklinglon.github.io/categories/K8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://marklinglon.github.io/tags/k8s/"}]},{"title":"Docker网络模型","slug":"docker/网络模型","date":"2021-06-20T16:00:00.000Z","updated":"2024-02-29T06:55:51.698Z","comments":true,"path":"2021/06/21/docker/网络模型/","link":"","permalink":"https://marklinglon.github.io/2021/06/21/docker/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"docker的七种网络模型 123456789101112131415Docker中常见的七种网络模型如下：Bridge（桥接）网络：默认的网络模型，用于在单个主机上连接容器。每个容器都有自己的网络命名空间，分配一个独立的IP地址，并通过桥接网络与主机通信。Host（主机）网络：容器与宿主机共享网络命名空间，直接使用宿主机的网络栈，因此网络通信速度最快。适用于需要最大化网络性能的场景，但会牺牲一定的网络隔离性。Overlay（覆盖）网络：在多个Docker守护程序或主机之间创建的虚拟网络。使用覆盖技术在底层物理网络之上构建虚拟网络，实现容器之间的跨主机通信。Macvlan（MAC虚拟化）网络：允许将容器直接映射到物理网络中的不同MAC地址，使其可以像物理设备一样进行通信。适用于需要容器直接与物理网络通信的场景。IPvlan（IP虚拟化）网络：类似于Macvlan，但是容器共享宿主机的MAC地址，但分配独立的IP地址。适用于需要容器直接与物理网络通信的场景。None（无网络）网络：容器没有默认的网络连接，需要用户自行配置网络。适用于特殊场景，如不需要网络连接的容器。Container（容器）网络：用户可以创建自定义的网络模型，根据特定需求配置网络。可以根据需要选择网络驱动程序、子网、网关等参数进行配置。 overlay和bridge网络模型的区别 12345678910111213141516Overlay网络和Bridge网络是Docker中两种不同的网络模型，它们有以下主要区别：Bridge（桥接）网络：桥接网络是 Docker 默认的网络模型。每个容器都有自己的网络命名空间，分配一个独立的IP地址。容器之间可以通过桥接网络进行通信，但默认情况下无法跨主机通信。桥接网络提供了一定程度的网络隔离。Overlay（覆盖）网络：覆盖网络是在多个Docker守护程序或主机之间创建的虚拟网络。它使用覆盖技术在底层物理网络之上构建虚拟网络，实现容器之间的跨主机通信。覆盖网络允许在集群中的多个主机上运行的容器相互通信，使得容器编排系统（如Kubernetes、Docker Swarm等）能够管理分布式应用。覆盖网络提供了更高级的网络功能，如服务发现、负载均衡等，适用于构建复杂的分布式系统。总的来说，桥接网络适用于单个主机上的容器通信，而覆盖网络适用于跨多个主机的容器通信，提供了更强大的网络功能和扩展性。 云厂商不选择macvlan和ipvlan的缘由 1234567891011在Docker网络模型中，macvlan和ipvlan是两种可选的网络模式，但一般情况下并不常用，原因如下：复杂性：macvlan和ipvlan网络模式相对于常规的桥接和覆盖网络模式更为复杂，配置和管理起来可能会更加困难。这增加了操作和维护的复杂性。网络限制：macvlan和ipvlan网络模式在某些网络环境下可能受到限制，特别是在虚拟化环境中。例如，一些虚拟化平台可能不支持macvlan或ipvlan模式。性能问题：虽然macvlan和ipvlan可以提供更接近物理网络的性能和隔离，但在某些情况下可能会导致性能下降。特别是在大规模容器部署中，可能会出现性能瓶颈。使用场景有限：macvlan和ipvlan适用于特定的网络场景，例如需要容器直接映射到物理网络的情况。然而，对于大多数应用程序和场景来说，桥接和覆盖网络模式已经足够满足需求，并且更容易配置和管理。综上所述，虽然macvlan和ipvlan提供了一些优势，但在大多数情况下，桥接和覆盖网络模式更为常用，更容易使用和管理。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://marklinglon.github.io/categories/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://marklinglon.github.io/tags/docker/"}]},{"title":"ArgoCD","slug":"CICD/argo-cd","date":"2021-01-20T16:00:00.000Z","updated":"2024-02-01T09:22:57.979Z","comments":true,"path":"2021/01/21/CICD/argo-cd/","link":"","permalink":"https://marklinglon.github.io/2021/01/21/CICD/argo-cd/","excerpt":"","text":"Argo CD 能落地 GitOps Argo CD 是以 Kubernetes 为基础设施的 GitOps 持续部署工具。下面是来自 Argo CD 社区的原理图： 强大而易扩展的 Argo CD 对于一般的 Kubernetes 运维场景，上面描述的功能是够用的。但是如果是复杂场景，涉及多云、多平台、多中间件，也是需要考虑的。 安装 在 Kubernetes 上部署 Argo CD 新建命名空间，部署 Argo CD 这里选择当前发布的最新版本: 1.8.3 12kubectl create namespace argocdkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/v1.8.3/manifests/install.yaml Argo CD 社区还提供了 HA 模式的部署方式，kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/v1.8.3/manifests/ha/install.yaml 用于生产环境。 查看服务 123456789kubectl -n argocd get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEargocd-dex-server ClusterIP 10.233.34.191 &lt;none&gt; 5556/TCP,5557/TCP,5558/TCP 5m37sargocd-metrics ClusterIP 10.233.54.3 &lt;none&gt; 8082/TCP 5m36sargocd-redis ClusterIP 10.233.18.86 &lt;none&gt; 6379/TCP 5m36sargocd-repo-server ClusterIP 10.233.3.171 &lt;none&gt; 8081/TCP,8084/TCP 5m36sargocd-server NodePort 10.233.61.3 223.*.*.* 80:31808/TCP,443:30992/TCP 5m36sargocd-server-metrics ClusterIP 10.233.36.228 &lt;none&gt; 8083/TCP 5m36s 查看 admin 账户密码 12345678910111213141516171819$ kc get secret -n argocd NAME TYPE DATA AGEargocd-application-controller-token-w2gdp kubernetes.io/service-account-token 3 182dargocd-applicationset-controller-token-q444h kubernetes.io/service-account-token 3 182dargocd-dex-server-token-mwfjf kubernetes.io/service-account-token 3 182dargocd-initial-admin-secret Opaque 1 182dargocd-notifications-controller-token-m4ctr kubernetes.io/service-account-token 3 182dargocd-notifications-secret Opaque 0 182dargocd-redis-token-pqx42 kubernetes.io/service-account-token 3 182dargocd-repo-server-token-zwnpz kubernetes.io/service-account-token 3 182dargocd-secret Opaque 9 182dargocd-server-token-cpv7l kubernetes.io/service-account-token 3 182ddefault-token-5vdwr kubernetes.io/service-account-token 3 182drepo-4178615321 Opaque 6 177dsh-gitops kubernetes.io/dockercfg 1 180d$ kc get secret -n argocd -o yaml argocd-initial-admin-secret echo &#x27;bkFFMElSbMFR1dnBiRA==&#x27;|base64 -d 访问页面 浏览器中打开https://223.../login (223..*.*不是真实ip,替换成您的ip)","categories":[{"name":"CICD","slug":"CICD","permalink":"https://marklinglon.github.io/categories/CICD/"}],"tags":[{"name":"gitops","slug":"gitops","permalink":"https://marklinglon.github.io/tags/gitops/"}]},{"title":"GitOps","slug":"CICD/gitops","date":"2021-01-20T16:00:00.000Z","updated":"2024-02-01T09:23:01.858Z","comments":true,"path":"2021/01/21/CICD/gitops/","link":"","permalink":"https://marklinglon.github.io/2021/01/21/CICD/gitops/","excerpt":"","text":"管理员密码 12admin管理员的密码可以通过命令获取：ARGO_PWD=`kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=&quot;&#123;.data.password&#125;&quot; | base64 -d` 用户管理 1234567kubectl edit cm argocd-rbac-cm -n argocdapiVersion: v1data: accounts.tom: apiKey,login accounts.tom.enabled: &quot;true&quot; accounts.lele: apiKey,login accounts.lele.enabled: &quot;true&quot; 生成密码 1234argocd account update-password --account tom --new-password 12345678 --current-password $ARGO_PWD或者argocd account update-password --account tom --new-password 12345678输入admin的密码 命令行登录 argocd login 10.100.16.250:8080 --username tom --password 1234 --insecure 命令行登出 argocd logout 10.100.16.250:8080 权限控制 用户权限控制：修改cm下的argocd-rbac-cm 1234567891011121314151617181920212223data: policy.csv: | p, role:gitops, applications, get, *, allow p, role:gitops, applications, create, *, allow p, role:gitops, applications, update, *, allow p, role:gitops, applications, sync, *, allow p, role:gitops, applications, override, *, allow p, role:gitops, repositories, get, *, allow p, role:gitops, repositories, create, *, allow p, role:gitops, repositories, update, *, allow p, role:gitops, projects, create, *, allow p, role:gitops, projects, get, *, allow p, role:gitops, clusters, get, *, allow p, role:gitops, clusters, list, *, allow g, tom, role:gitops apiVersion: v1 kind: ConfigMap metadata: labels: app.kubernetes.io/name: argocd-rbac-cm app.kubernetes.io/part-of: argocd name: argocd-rbac-cm namespace: argocd 注意：必须增加 g, tom, role:gitops 将 tom 用户加到 gitops 这个 role 中。 生成token 1234567export ARGOCD_SERVER=10.100.16.250:8080wget http://$&#123;ARGOCD_SERVER&#125;/download/argocd-linux-amd64 --no-check-certificatemv argocd-linux-amd64 /usr/local/bin/argocdchmod 751 /usr/local/bin/argocdargocd login 10.100.16.250:8080argocd_api_token=`argocd account generate-token -a cnc-api` // token可以在web控制台生成export ARGOCD_AUTH_TOKEN=$&#123;argocd_api_token&#125; 同步application，如果没有禁用tls，就不需要加–insecure |–plaintext 12argocd app sync apps --auth-token $ARGOCD_AUTH_TOKEN --server 10.100.16.250:8080 --insecure argocd app wait apps --auth-token $ARGOCD_AUTH_TOKEN --server 10.100.16.250:8080 --insecure 状态 OutOfSync：已经部署的应用程序的实际状态与目标状态有差异，则被认为是 OutOfSync 状态 web-base-terminal 12345678910111213Enabling the terminal¶Set the exec.enabled key to &quot;true&quot; on the argocd-cm ConfigMap.Patch the argocd-server Role (if using namespaced Argo) or ClusterRole (if using clustered Argo) to allow argocd-server to exec into pods- apiGroups: - &quot;&quot; resources: - pods/exec verbs: - createAdd RBAC rules to allow your users to create the exec resource, i.e.p, role:myrole, exec, create, */*, allow webhook,git提交后立即触发argocd sync ,触发webhook需要添加argocd接口白名单，还是得用gitlab 123456789101. gitlab/github 配置webhook http://10.100.16.250:8080/api/webhookapplication/jsontest6662. echo test666 |base64 -w 0WW9sdfyaGE2NjY4OD3. kubectl edit secret argocd-secret -n argocd stringData: # github webhook secret webhook.github.secret: WW9sdfyaGE2NjY4OD 健康检查 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586$ kc get configmap -n argocd argocd-cm -o yaml apiVersion: v1data: accounts.cnc-api: apiKey accounts.cnc-api.enabled: &quot;true&quot; exec.enabled: &quot;true&quot; resource.customizations.health.apps.kruise.io_SidecarSet: | hs = &#123;&#125; -- if paused if obj.spec.updateStrategy.paused then hs.status = &quot;Suspended&quot; hs.message = &quot;SidecarSet is Suspended&quot; return hs end -- check sidecarSet status if obj.status ~= nil then if obj.status.observedGeneration &lt; obj.metadata.generation then hs.status = &quot;Progressing&quot; hs.message = &quot;Waiting for rollout to finish: observed sidecarSet generation less then desired generation&quot; return hs end if obj.status.matchedPods == 0 then hs.status = &quot;Healthy&quot; return hs end if obj.status.updatedPods ~= obj.status.matchedPods then hs.status = &quot;Progressing&quot; hs.message = &quot;Waiting for rollout to finish: replicas hasn&#x27;t finished updating...&quot; return hs end if obj.status.readyPods ~= obj.status.matchedPods then hs.status = &quot;Progressing&quot; hs.message = &quot;Waiting for rollout to finish: replicas hasn&#x27;t finished updating...&quot; return hs end hs.status = &quot;Healthy&quot; return hs end -- if status == nil hs.status = &quot;Progressing&quot; hs.message = &quot;Waiting for sidecarSet&quot; return hs resource.customizations.health.argoproj.io_Application: | hs = &#123;&#125; hs.status = &quot;Progressing&quot; hs.message = &quot;&quot; if obj.status ~= nil then if obj.status.health ~= nil then hs.status = obj.status.health.status if obj.status.health.message ~= nil then hs.message = obj.status.health.message end end end return hs resource.customizations.health.kubegame.tencent.com_Tcaplus: | hs = &#123;&#125; if obj.status ~= nil then if obj.status.status == &quot;Complete&quot; then hs.status = &quot;Healthy&quot; hs.message = obj.status.tableInfo return hs end end hs.status = &quot;Progressing&quot; hs.message = &quot;Waiting for tcaplus&quot; return hs resource.customizations.knownTypeFields.tkex.tencent.com_GameDeployment: | - field: spec.template.spec type: core/v1/PodSpec resource.customizations.knownTypeFields.tkex.tencent.com_GameStatefulSet: | - field: spec.template.spec type: core/v1/PodSpeckind: ConfigMapmetadata: labels: app.kubernetes.io/name: argocd-cm app.kubernetes.io/part-of: argocd name: argocd-cm namespace: argocd","categories":[{"name":"CICD","slug":"CICD","permalink":"https://marklinglon.github.io/categories/CICD/"}],"tags":[{"name":"gitops","slug":"gitops","permalink":"https://marklinglon.github.io/tags/gitops/"}]},{"title":"Redis常见问题","slug":"中间件/redis","date":"2021-01-20T16:00:00.000Z","updated":"2024-02-01T09:24:01.003Z","comments":true,"path":"2021/01/21/中间件/redis/","link":"","permalink":"https://marklinglon.github.io/2021/01/21/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/","excerpt":"","text":"穿透（Cache Penetration）： 穿透指的是恶意请求或查询缓存中不存在的数据，导致请求直接落在后端存储上，消耗了后端资源。这种情况下，缓存无法起到预期的作用，也没有命中率。常见的攻击方式是使用不存在的键进行请求。 解决穿透问题的常见方法是使用布隆过滤器（Bloom Filter）或简单的缓存校验来过滤掉不存在的键。布隆过滤器是一种高效的数据结构，用于判断一个元素是否属于一个集合中，可以快速过滤掉不存在的键，减轻后端存储的压力。 击穿（Cache Miss）： 击穿指的是在高并发情况下，当一个请求查询 Redis 中不存在的数据时，导致请求直接落在后端存储上，增加了后端的负载并降低了性能。这是因为查询不存在的数据时，Redis 无法缓存该数据，每次请求都需要访问后端存储。 解决击穿问题的常见方法是使用互斥锁（Mutex Lock）或分布式锁，在第一个查询发现数据不存在时，将锁加上，其他请求在锁未释放之前直接返回，避免了对后端存储的直接访问。同时，可以使用热点数据预加载或设置合理的缓存过期时间，减少对后端存储的访问。 雪崩（Cache Avalanche）： 雪崩指的是在缓存过期时间到达时，大量的请求同时查询该数据，导致所有请求都落在后端存储上，造成后端存储压力骤增，甚至导致后端服务不可用。这是因为缓存过期后，所有请求都会直接访问后端存储获取数据。 解决雪崩问题的常见方法是使用分布式缓存的多级缓存架构，如设置热点数据永不过期、使用不同的缓存过期时间、采用异步缓存更新策略等。此外，还可以使用限流、降级和熔断等技术手段，保护后端存储不被大量请求压垮。 缓存穿透解决方案 缓存穿透是查询不存在的数据时会访问数据库 有两种方法： 布隆过滤器：将数据库中的数据哈希映射到bitmap（0、1表示存在、不存在），查询时先访问bitmap，查询不存在的数据就会被bitmap拦截，就不用进入数据库查询 返回空值给缓存：当查询不存在数据访问数据库返回值为空，仍然将空值进行缓存（Redis中value为空值会被回收，可以设置empty字符串等），当然插入值时要替代掉空值 缓存击穿解决方案 缓存击穿是数据缓存没有而数据库有，查询时需要进入数据库查询，高并发时会压垮数据库 有两种解决方案： 设置热点key永不过期 加互斥锁（mutex key） 互斥锁：在缓存失效的时候（判断拿出来的值为空），第1个进入的线程，获取锁并从数据库去取数据，没释放锁之前，其他并行进入的线程会等待，再重新去缓存取数据 Redis：使用setnx操作去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。 setnx key value：当key不存在时才设置值，key存在不操作。setnx可以实现互斥锁 通过互斥锁，高并发也仅查询一次数据库 缓存雪崩解决方案 缓存雪崩是缓存服务器重启或者大量缓存失效，引起数据库压力过大 这里的问题是多个key缓存，有两种方案： 尽量设置缓存失效时间均匀分布，别在短时间内大量缓存过期 考虑用加锁队列的方式来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求数据库（在高并发下线程阻塞，用户体验差）","categories":[{"name":"中间件","slug":"中间件","permalink":"https://marklinglon.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://marklinglon.github.io/tags/redis/"}]},{"title":"Elasticsearch常见面试题","slug":"中间件/elastic面试题","date":"2021-01-20T16:00:00.000Z","updated":"2024-02-01T09:22:51.555Z","comments":true,"path":"2021/01/21/中间件/elastic面试题/","link":"","permalink":"https://marklinglon.github.io/2021/01/21/%E4%B8%AD%E9%97%B4%E4%BB%B6/elastic%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"","text":"1、什么是Elasticsearch，它是用来做什么的？ Elasticsearch是一个开源的分布式搜索引擎，用于快速、准确地搜索和分析大量数据。它是基于全文搜索引擎库Lucene构建的，因此具有全文搜索、实时搜索、分布式搜索、数据分析等功能。Elasticsearch可用于构建各种类型的应用程序，例如电商网站的商品搜索、新闻网站的文章搜索、企业内部的日志分析和监控等。 2、Elasticsearch与传统数据库的区别是什么？ Elasticsearch与传统数据库最大的不同是，它是基于全文搜索引擎库Lucene构建的，因此具有全文搜索、实时搜索、分布式搜索、数据分析等功能，而传统数据库更适合于事务处理等关系型数据操作。传统数据库通常采用结构化查询语言（SQL）进行查询，而Elasticsearch使用JSON格式的查询语法，更加灵活和强大。 3、Elasticsearch的架构是怎样的？请简单介绍一下。 Elasticsearch的架构是分布式的，包括多个节点，每个节点可以是主节点或数据节点。主节点负责集群管理和负载均衡等任务，数据节点负责存储和检索数据。每个节点都可以自由加入或退出集群，具有自动发现和自动平衡功能。Elasticsearch还具有分片和副本机制，可以将一个索引分成多个部分，每个部分称为一个分片，每个分片可以有多个副本，以提高数据冗余和可用性。 4、Elasticsearch的数据是如何存储的？ Elasticsearch的数据存储在分片中，每个分片存储一部分数据。每个分片可以有多个副本，以提高数据冗余和可用性。数据存储在Lucene索引中，每个索引包含一个或多个分片，每个分片都是一个独立的Lucene索引。每个文档都存储在一个分片中，每个文档都有一个唯一的ID和一个版本号，以便进行版本控制和冲突检测。 5、Elasticsearch和solr的区别 Elasticsearch（ES）和Solr都是流行的开源搜索引擎，它们都基于Apache Lucene搜索库开发而来，但在一些方面有所不同： 架构：ES是分布式架构，具有分片和副本机制，支持自动水平扩展，而Solr是基于主从架构，需要手动进行复制和分片。 搜索语法：ES使用JSON格式的查询语法，而Solr使用XML格式的查询语法。 数据处理：ES支持实时数据处理和分析，可以通过Logstash和Kibana进行数据采集和展示，而Solr则更专注于搜索和文本分析功能。 社区和生态系统：ES拥有更大的社区和生态系统，拥有丰富的插件和工具，而Solr则更专注于搜索功能本身。 总的来说，ES更适合处理实时数据、分析、日志等场景，而Solr则更适合于搜索和文本分析场景。选择哪个搜索引擎要根据实际需求和技术栈来进行权衡。 6、Elasticsearch的倒排索引 Elasticsearch的核心功能之一就是全文搜索，而全文搜索的实现离不开倒排索引（Inverted Index）。 倒排索引是一种用于全文搜索的数据结构，它将单词（Term）映射到包含该单词的文档（Document）中。与传统的顺序索引（Forward Index）不同，顺序索引将文档映射到包含的单词中。因此，倒排索引可以更快地对大量文本进行搜索，而且支持复杂的查询和聚合操作。 在Elasticsearch中，每个索引都包含一个或多个分片（Shard），每个分片包含一个倒排索引。当一个文档被索引时，Elasticsearch会对文档中的所有字段进行分词（Tokenize）和过滤（Filter），生成多个单词（Term）。然后将每个单词与其所在的文档映射，形成一个倒排索引。 例如，假设我们有一个包含以下两个文档的索引： 1&#123; &quot;title&quot;: &quot;The quick brown fox&quot;, &quot;content&quot;: &quot;Jump over the lazy dog&quot; &#125; &#123; &quot;title&quot;: &quot;The quick brown rabbit&quot;, &quot;content&quot;: &quot;Run around the green grass&quot; &#125; 当这些文档被索引时，Elasticsearch会生成以下倒排索引： 1&#123; &quot;brown&quot;: [1, 2], &quot;dog&quot;: [1], &quot;fox&quot;: [1], &quot;grass&quot;: [2], &quot;green&quot;: [2], &quot;jump&quot;: [1], &quot;lazy&quot;: [1], &quot;over&quot;: [1], &quot;quick&quot;: [1, 2], &quot;rabbit&quot;: [2], &quot;run&quot;: [2], &quot;the&quot;: [1, 2] &#125; 在这个倒排索引中，每个单词都映射到包含该单词的文档的ID列表。例如，单词&quot;brown&quot;映射到文档1和2，单词&quot;dog&quot;映射到文档1。 当进行全文搜索时，Elasticsearch会将查询语句分词并查找包含所有查询单词的文档。例如，如果我们搜索&quot;quick brown&quot;, Elasticsearch会查找包含单词&quot;quick&quot;和&quot;brown&quot;的文档，找到文档1和2。 倒排索引是Elasticsearch实现全文搜索的关键。它可以加快搜索速度，并支持复杂的查询和聚合操作。 7、Elasticsearch的索引是什么意思？如何创建一个索引？ 在Elasticsearch中，索引（Index）是一种用于存储和搜索数据的数据结构。它类似于关系型数据库中的表，但具有更灵活的结构和更快的搜索速度。索引可以包含多个文档（Document），每个文档可以是不同类型的数据，但它们都必须属于同一个索引。 在Elasticsearch中，可以使用PUT命令来创建一个索引。以下是创建名为myindex的索引的示例： 1PUT /myindex &#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 0 &#125;, &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;description&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125; &#125; 在这个示例中，我们使用PUT命令创建一个名为myindex的索引，并设置了以下属性： settings: 索引的设置，例如分片数和副本数等。 mappings: 索引中包含的字段的类型和属性，例如文本字段和数字字段等。 在这个示例中，我们定义了一个包含title和description字段的索引，它们的类型都是text。我们还设置了分片数为1，副本数为0，表示该索引只有一个分片，没有副本。 可以使用GET命令来检索索引的信息，例如： 1GET /myindex 这将返回myindex索引的详细信息，包括它的设置和字段映射等。 8、什么是文档(Document)？如何创建一个文档？ 在Elasticsearch中，文档（Document）是一种基本的数据单元，它类似于关系型数据库中的一行数据，但具有更灵活的结构和更快的搜索速度。文档可以包含任意数量的字段，每个字段可以是不同类型的数据。 在Elasticsearch中，可以使用PUT命令将文档添加到索引中。以下是创建一个包含title、content和tags字段的文档的示例： 1PUT /myindex/_doc/1 &#123; &quot;title&quot;: &quot;My first document&quot;, &quot;content&quot;: &quot;This is the content of my first document&quot;, &quot;tags&quot;: [&quot;tag1&quot;, &quot;tag2&quot;] &#125; 在这个示例中，我们使用PUT命令将一个名为1的文档添加到名为myindex的索引中，文档包含了title、content和tags字段。可以根据需要添加或删除字段，或者更改字段中的数据。 可以使用GET命令来检索文档的信息，例如： 1GET /myindex/_doc/1 这将返回文档1的详细信息，包括它的字段和数据等。 可以使用POST命令将文档添加到索引中，而不需要指定文档ID。Elasticsearch会自动生成一个唯一的ID，并将文档添加到索引中。例如： 1POST /myindex/_doc &#123; &quot;title&quot;: &quot;My second document&quot;, &quot;content&quot;: &quot;This is the content of my second document&quot;, &quot;tags&quot;: [&quot;tag1&quot;, &quot;tag3&quot;] &#125; 这将创建一个新的文档，并自动生成一个唯一的ID。可以使用GET命令来检索新创建的文档的信息。 9、什么是分片(Shard)和副本(Replica)？它们有什么作用？ 在Elasticsearch中，分片（Shard）和副本（Replica）是用于处理和存储数据的重要概念。它们的作用是提高系统的性能、可用性和可伸缩性。 分片是将索引拆分为多个部分的过程，每个部分称为一个分片。每个分片都是一个独立的Lucene索引，它可以在集群中的任何节点上存储和处理数据。分片的数量是在索引创建时指定的，通常根据数据量和系统负载等因素进行调整。分片可以提高搜索速度和可伸缩性，因为它们可以在多个节点上并行处理搜索请求。 副本是分片的一份完全相同的拷贝，它可以在集群中的其他节点上存储。副本的数量也是在索引创建时指定的，通常用于提高系统的可用性和容错性。当一个节点无法处理请求时，副本可以接管它的工作，确保系统的连续性。副本还可以提高搜索速度，因为它们可以在多个节点上并行处理搜索请求。 例如，假设我们有一个包含10个分片和2个副本的索引。这意味着数据将被分成10个部分，每个部分都存储在不同的节点上，并且每个分片都有2个完全相同的副本，分别存储在其他节点上。这样可以提高系统的性能、可用性和可伸缩性，因为它可以同时处理多个搜索请求，并在节点故障时保持系统连续性。 分片和副本是Elasticsearch实现高性能和高可用性的关键。通过合理地配置它们，可以提高系统的性能、可用性和可伸缩性，并确保数据的安全性和连续性。 10、Elasticsearch中的查询(Query)有哪些类型？请分别举例说明。 在Elasticsearch中，查询（Query）是用于搜索文档的重要概念。它们可以帮助用户快速准确地找到所需的文档。Elasticsearch支持多种类型的查询，常见的查询类型如下： Match Query Match Query是一种基本的查询类型，它会在指定字段中搜索包含给定关键字的文档。例如： 1GET /myindex/_search &#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;elasticsearch&quot; &#125; &#125; &#125; 这个查询将返回包含单词&quot;elasticsearch&quot;的title字段的所有文档。 Term Query Term Query是一种精确匹配查询类型，它会在指定字段中搜索精确匹配给定值的文档。例如： 1GET /myindex/_search &#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; &quot;status&quot;: &quot;published&quot; &#125; &#125; &#125; 这个查询将返回status字段值为&quot;published&quot;的所有文档。 Range Query Range Query是一种范围查询类型，它会在指定字段中搜索在给定范围内的值的文档。例如： 1GET /myindex/_search &#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; &quot;price&quot;: &#123; &quot;gte&quot;: 10, &quot;lt&quot;: 20 &#125; &#125; &#125; &#125; 这个查询将返回price字段值在10到20之间的所有文档。 Bool Query Bool Query是一种复合查询类型，它可以组合多个查询条件使用bool操作符进行逻辑组合。例如： 1GET /myindex/_search &#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;elasticsearch&quot; &#125;&#125;, &#123; &quot;range&quot;: &#123; &quot;price&quot;: &#123; &quot;gte&quot;: 10, &quot;lt&quot;: 20 &#125;&#125;&#125; ], &quot;must_not&quot;: [ &#123; &quot;term&quot;: &#123; &quot;status&quot;: &quot;draft&quot; &#125;&#125; ], &quot;should&quot;: [ &#123; &quot;match&quot;: &#123; &quot;category&quot;: &quot;books&quot; &#125;&#125;, &#123; &quot;match&quot;: &#123; &quot;category&quot;: &quot;movies&quot; &#125;&#125; ] &#125; &#125; &#125; 这个查询将返回满足以下条件的文档：title字段包含&quot;elasticsearch&quot;、price字段在10到20之间、status字段不为&quot;draft&quot;，并且category字段包含&quot;books&quot;或&quot;movies&quot;之一。 以上是常见的一些查询类型，Elasticsearch还支持其他类型的查询，如Wildcard Query、Phrase Query、Fuzzy Query等，可以根据实际需求选择合适的查询类型。 11、Elasticsearch中的过滤器(Filter)有哪些类型？请分别举例说明。 在Elasticsearch中，过滤器（Filter）是用于过滤文档的重要概念，它可以帮助用户快速准确地筛选出所需的文档。与查询不同，过滤器不会影响文档的得分，而只是根据指定的条件过滤掉不符合条件的文档，从而提高查询的效率。Elasticsearch支持多种类型的过滤器，常见的过滤器类型如下： Term Filter Term Filter是一种精确匹配过滤器类型，它会根据指定字段和值精确匹配过滤掉不符合条件的文档。例如： 1GET /myindex/_search &#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; &quot;term&quot;: &#123; &quot;status&quot;: &quot;published&quot; &#125; &#125; &#125; &#125; &#125; 这个过滤器将过滤掉status字段值不为&quot;published&quot;的所有文档。 Range Filter Range Filter是一种范围过滤器类型，它会根据指定字段和范围过滤掉不符合条件的文档。例如： 1GET /myindex/_search &#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;price&quot;: &#123; &quot;gte&quot;: 10, &quot;lt&quot;: 20 &#125; &#125; &#125; &#125; &#125; &#125; 这个过滤器将过滤掉price字段值不在10到20之间的所有文档。 Bool Filter Bool Filter是一种复合过滤器类型，它可以组合多个过滤条件使用bool操作符进行逻辑组合。例如： 1GET /myindex/_search &#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: [ &#123; &quot;term&quot;: &#123; &quot;status&quot;: &quot;published&quot; &#125;&#125;, &#123; &quot;range&quot;: &#123; &quot;price&quot;: &#123; &quot;gte&quot;: 10, &quot;lt&quot;: 20 &#125;&#125;&#125; ] &#125; &#125; &#125; 这个过滤器将过滤掉满足以下条件之一的文档：status字段不为&quot;published&quot;，或者price字段不在10到20之间。 Exists Filter Exists Filter是一种存在过滤器类型，它会过滤掉指定字段不存在的文档。例如： 1GET /myindex/_search &#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; &quot;exists&quot;: &#123; &quot;field&quot;: &quot;category&quot; &#125; &#125; &#125; &#125; &#125; 这个过滤器将过滤掉不包含category字段的所有文档。 以上是常见的一些过滤器类型，Elasticsearch还支持其他类型的过滤器，如Wildcard Filter、Geo Distance Filter、Script Filter等，可以根据实际需求选择合适的过滤器类型。 12、什么是聚合(Aggregation)？请举例说明。 在Elasticsearch中，聚合（Aggregation）是一种用于计算和统计文档数据的重要概念。聚合可以根据指定的条件对文档进行分组、计算、统计等操作，从而帮助用户深入了解数据的特征和分布情况，支持用户进行更深入的数据分析和决策。Elasticsearch支持多种类型的聚合，常见的聚合类型如下： Terms Aggregation Terms Aggregation是一种基本的聚合类型，它会根据指定字段对文档进行分组，并统计每个分组中的文档数量。例如： 1GET /myindex/_search &#123; &quot;aggs&quot;: &#123; &quot;group_by_category&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;category&quot; &#125; &#125; &#125; &#125; 这个聚合将根据category字段对文档进行分组，并统计每个分组中的文档数量。 Range Aggregation Range Aggregation是一种范围聚合类型，它会根据指定字段和范围将文档分组，并统计每个分组中的文档数量。例如： 1GET /myindex/_search &#123; &quot;aggs&quot;: &#123; &quot;group_by_price_range&quot;: &#123; &quot;range&quot;: &#123; &quot;field&quot;: &quot;price&quot;, &quot;ranges&quot;: [ &#123; &quot;from&quot;: 0, &quot;to&quot;: 10 &#125;, &#123; &quot;from&quot;: 10, &quot;to&quot;: 20 &#125;, &#123; &quot;from&quot;: 20, &quot;to&quot;: 30 &#125; ] &#125; &#125; &#125; &#125; 这个聚合将根据price字段的不同范围对文档进行分组，并统计每个分组中的文档数量。 Date Histogram Aggregation Date Histogram Aggregation是一种时间聚合类型，它会根据指定的时间字段将文档分组，并按照时间间隔统计每个分组中的文档数量。例如： 1GET /myindex/_search &#123; &quot;aggs&quot;: &#123; &quot;group_by_date&quot;: &#123; &quot;date_histogram&quot;: &#123; &quot;field&quot;: &quot;created_at&quot;, &quot;interval&quot;: &quot;day&quot; &#125; &#125; &#125; &#125; 这个聚合将根据created_at字段的日期对文档进行分组，并按天为时间间隔统计每个分组中的文档数量。 Metrics Aggregation Metrics Aggregation是一种度量聚合类型，它会对文档中的数字字段进行统计，例如计算平均值、最大值、最小值、总和等。例如： 1GET /myindex/_search &#123; &quot;aggs&quot;: &#123; &quot;avg_price&quot;: &#123; &quot;avg&quot;: &#123; &quot;field&quot;: &quot;price&quot; &#125; &#125; &#125; &#125; 这个聚合将计算文档中price字段的平均值。 以上是常见的一些聚合类型，Elasticsearch还支持其他类型的聚合，如Nested Aggregation、Geo Distance Aggregation、Scripted Metric Aggregation等，可以根据实际需求选择合适的聚合类型。 13、Elasticsearch中的排序(Sort)有哪些类型？请分别举例说明。 在Elasticsearch中，排序（Sort）是一种用于排序搜索结果的重要概念。排序可以根据指定的条件对搜索结果进行排序，支持按照文档中的某个字段、某个复合条件等进行排序，从而帮助用户更快地找到所需的文档。Elasticsearch支持多种类型的排序，常见的排序类型如下： Field Sort Field Sort是一种基本的排序类型，它会按照指定字段的值对搜索结果进行排序。例如： 1GET /myindex/_search &#123; &quot;sort&quot;: [ &#123; &quot;price&quot;: &#123; &quot;order&quot;: &quot;asc&quot; &#125;&#125; ] &#125; 这个排序将按照price字段的值对搜索结果进行升序排序。 Score Sort Score Sort是一种按照文档得分进行排序的类型，它会按照搜索匹配程度对搜索结果进行排序。例如： 1GET /myindex/_search &#123; &quot;sort&quot;: [ &#123; &quot;_score&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125;&#125; ] &#125; 这个排序将按照搜索匹配程度对搜索结果进行降序排序。 Script Sort Script Sort是一种使用脚本进行排序的类型，它可以根据自定义的脚本对搜索结果进行排序。例如： 1GET /myindex/_search &#123; &quot;sort&quot;: [ &#123; &quot;_script&quot;: &#123; &quot;type&quot;: &quot;number&quot;, &quot;script&quot;: &#123; &quot;source&quot;: &quot;doc[&#x27;price&#x27;].value * params.factor&quot;, &quot;params&quot;: &#123; &quot;factor&quot;: 1.5 &#125; &#125;, &quot;order&quot;: &quot;desc&quot; &#125; &#125; ] &#125; 这个排序将根据自定义脚本对搜索结果进行排序，脚本计算方式为price字段值乘以1.5。 Geo Distance Sort Geo Distance Sort是一种根据地理位置距离进行排序的类型，它会按照指定地理位置与文档中的地理位置字段之间的距离进行排序。例如： 1GET /myindex/_search &#123; &quot;sort&quot;: [ &#123; &quot;_geo_distance&quot;: &#123; &quot;location&quot;: &#123; &quot;lat&quot;: 40.73, &quot;lon&quot;: -73.99 &#125;, &quot;order&quot;: &quot;asc&quot;, &quot;unit&quot;: &quot;km&quot; &#125; &#125; ] &#125; 这个排序将按照搜索结果中每个文档的location字段与指定的地理位置之间的距离从小到大排序。 以上是常见的一些排序类型，Elasticsearch还支持其他类型的排序，如Nested Sort、Scripted Sort等，可以根据实际需求选择合适的排序类型。 14、什么是Mapping？如何定义一个Mapping？ 在Elasticsearch中，Mapping是用于定义索引中文档结构和字段的重要概念。Mapping定义了每个字段的数据类型、分词器、索引方式等信息，Elasticsearch使用Mapping来确定如何解析、存储和索引文档中的数据。一个索引可以有一个或多个Mapping，每个Mapping对应一个文档类型。在定义Mapping之后，每个文档都必须符合Mapping定义的结构，否则就无法被索引和搜索。 定义一个Mapping可以通过以下步骤完成： 创建索引 首先需要创建一个索引，可以使用PUT API指定索引名称和索引参数。例如： 1PUT /myindex &#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 0 &#125; &#125; 这个请求将创建一个名为myindex的索引，设置分片数为1，副本数为0。 定义Mapping 接下来需要定义Mapping，可以使用PUT API指定索引名称和Mapping定义。例如： 1PUT /myindex/_mapping &#123; &quot;properties&quot;: &#123; &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;standard&quot; &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;english&quot; &#125;, &quot;price&quot;: &#123; &quot;type&quot;: &quot;float&quot; &#125;, &quot;created_at&quot;: &#123; &quot;type&quot;: &quot;date&quot;, &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot; &#125; &#125; &#125; 这个请求将在myindex索引中定义一个Mapping，包括四个字段：title、content、price、created_at。title和content字段的类型为text，分别使用standard和english分词器；price字段的类型为float；created_at字段的类型为date，格式为yyyy-MM-dd HH:mm:ss。 在定义Mapping时，可以根据需要设置不同的参数，如数据类型、分词器、索引方式、复杂类型等。Mapping定义完成后，可以开始向索引中添加文档，每个文档必须符合Mapping定义的结构，否则就无法被索引和搜索。 需要注意的是，Mapping一旦定义后就不能更改，只能重新创建索引并重新索引数据。因此在设计Mapping时需要考虑到未来可能的数据变化和业务需求，避免频繁更改Mapping造成不必要的麻烦。 15、什么是Analyzer？如何定义一个Analyzer？ 在Elasticsearch中，Analyzer是用于将文本数据分解成单词（Term）并进行标准化和归一化的重要概念。Analyzer由一系列Token Filter和一个可选的Character Filter组成，可以根据不同的需求进行配置和定制。Analyzer在索引时用于将文本数据分解成单词，同时在搜索时也会用到，对搜索查询的关键词进行相同的分解和标准化，从而提高搜索结果的匹配度。 定义一个Analyzer可以通过以下步骤完成： 定义Char Filter 首先可以定义一个Char Filter，它将被用于对文本进行字符级别的处理，如移除HTML标签、转换大小写等。例如： 1PUT /myindex/_settings &#123; &quot;analysis&quot;: &#123; &quot;char_filter&quot;: &#123; &quot;my_char_filter&quot;: &#123; &quot;type&quot;: &quot;html_strip&quot; &#125; &#125; &#125; &#125; 这个请求将定义一个名为my_char_filter的Char Filter，它将移除文本中的HTML标签。 定义Token Filter 接下来可以定义一个或多个Token Filter，它们将被用于对文本进行单词级别的处理，如分词、移除停用词、词干提取等。例如： 1PUT /myindex/_settings &#123; &quot;analysis&quot;: &#123; &quot;filter&quot;: &#123; &quot;my_stopwords&quot;: &#123; &quot;type&quot;: &quot;stop&quot;, &quot;stopwords&quot;: [&quot;and&quot;, &quot;the&quot;, &quot;a&quot;] &#125;, &quot;my_stemmer&quot;: &#123; &quot;type&quot;: &quot;stemmer&quot;, &quot;name&quot;: &quot;english&quot; &#125; &#125; &#125; &#125; 这个请求将定义两个Token Filter，分别为my_stopwords和my_stemmer。my_stopwords将移除停用词（and、the、a），而my_stemmer将使用英语词干提取器进行词干提取。 定义Analyzer 最后可以定义一个Analyzer，它将由一个Char Filter和一个或多个Token Filter组成。例如： 1PUT /myindex/_settings &#123; &quot;analysis&quot;: &#123; &quot;analyzer&quot;: &#123; &quot;my_analyzer&quot;: &#123; &quot;type&quot;: &quot;custom&quot;, &quot;char_filter&quot;: [&quot;my_char_filter&quot;], &quot;tokenizer&quot;: &quot;standard&quot;, &quot;filter&quot;: [&quot;lowercase&quot;, &quot;my_stopwords&quot;, &quot;my_stemmer&quot;] &#125; &#125; &#125; &#125; 这个请求将定义一个名为my_analyzer的Analyzer，它由一个Char Filter（my_char_filter）、一个Tokenizer（standard）和三个Token Filter（lowercase、my_stopwords、my_stemmer）组成。my_analyzer将对文本进行字符级别的处理（my_char_filter）、将文本分解成单词（standard Tokenizer），并对单词进行小写转换、移除停用词、词干提取等处理。 通过以上步骤定义好Analyzer后，就可以在Mapping中将该Analyzer应用到文本字段上，从而在索引和搜索时使用该Analyzer对文本进行标准化和归一化处理，提高搜索结果的匹配度。 需要注意的是，Analyzer是一种全局配置，它将对整个索引中的文本数据进行处理。因此在设计Analyzer时需要考虑到业务需求和实际数据，避免不必要的处理和错误结果。 16、Elasticsearch中的分词器(Tokenizer)有哪些类型？请分别举例说明。 在Elasticsearch中，分词器（Tokenizer）是用于将文本数据分解为单词（Term）的重要概念。分词器是索引和搜索过程中的核心组件，它决定了文本数据如何被分解和处理，从而影响了搜索结果的匹配度和准确性。Elasticsearch支持多种类型的分词器，常见的分词器类型如下： Standard Tokenizer Standard Tokenizer是一种最常用的分词器，它将文本数据按照空格和标点符号进行分解，并将单词转换成小写形式。例如： 1GET /_analyze &#123; &quot;tokenizer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;The quick brown fox jumped over the lazy dog.&quot; &#125; 这个请求将使用Standard Tokenizer对&quot;The quick brown fox jumped over the lazy dog.&quot;进行分解，得到单词序列[“the”, “quick”, “brown”, “fox”, “jumped”, “over”, “the”, “lazy”, “dog”]。 Whitespace Tokenizer Whitespace Tokenizer是一种按照空格进行分解的分词器，它将文本数据按照空格进行分解，并保留单词中的大小写形式。例如： 1GET /_analyze &#123; &quot;tokenizer&quot;: &quot;whitespace&quot;, &quot;text&quot;: &quot;The quick brown fox jumped over the lazy dog.&quot; &#125; 这个请求将使用Whitespace Tokenizer对&quot;The quick brown fox jumped over the lazy dog.&quot;进行分解，得到单词序列[“The”, “quick”, “brown”, “fox”, “jumped”, “over”, “the”, “lazy”, “dog.”]。 Keyword Tokenizer Keyword Tokenizer是一种将整个文本数据作为一个单词进行索引和搜索的分词器，它通常用于精确匹配和过滤。例如： 1GET /_analyze &#123; &quot;tokenizer&quot;: &quot;keyword&quot;, &quot;text&quot;: &quot;The quick brown fox jumped over the lazy dog.&quot; &#125; 这个请求将使用Keyword Tokenizer对&quot;The quick brown fox jumped over the lazy dog.&quot;进行分解，得到单词序列[“The quick brown fox jumped over the lazy dog.”]。 Path Hierarchy Tokenizer Path Hierarchy Tokenizer是一种将路径数据分解为多个层次的分词器，它通常用于处理文件路径等数据。例如： 1GET /_analyze &#123; &quot;tokenizer&quot;: &quot;path_hierarchy&quot;, &quot;text&quot;: &quot;/home/user/documents/myfile.txt&quot; &#125; 这个请求将使用Path Hierarchy Tokenizer对&quot;/home/user/documents/myfile.txt&quot;进行分解，得到单词序列[“/”, “/home”, “/home/user”, “/home/user/documents”, “/home/user/documents/myfile.txt”]。 除了以上常见的分词器类型，Elasticsearch还支持其他类型的分词器，如EdgeNGram Tokenizer、Ngram Tokenizer、Pattern Tokenizer等，可以根据实际需求选择合适的分词器类型。 17、Elasticsearch中的过滤器(Filter)有哪些类型？请分别举例说明。 在Elasticsearch中，过滤器（Filter）是用于对搜索结果进行过滤和筛选的重要概念。过滤器可以根据指定的条件对搜索结果进行过滤，例如按照文档的某个字段、某个范围、某个词条等进行过滤，从而帮助用户更快地找到所需的文档。Elasticsearch支持多种类型的过滤器，常见的过滤器类型如下： Term Filter Term Filter是一种按照词条进行过滤的过滤器，它可以根据指定的字段和值来匹配文档。例如： 1GET /myindex/_search &#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; &quot;term&quot;: &#123; &quot;category&quot;: &quot;books&quot; &#125; &#125; &#125; &#125; &#125; 这个请求将按照category字段的值为books来过滤搜索结果。 Range Filter Range Filter是一种按照范围进行过滤的过滤器，它可以根据指定的字段和范围来匹配文档。例如： 1GET /myindex/_search &#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; &quot;range&quot;: &#123; &quot;price&quot;: &#123; &quot;gte&quot;: 10, &quot;lt&quot;: 50 &#125; &#125; &#125; &#125; &#125; &#125; 这个请求将按照price字段的值在10和50之间来过滤搜索结果。 Exists Filter Exists Filter是一种按照字段是否存在进行过滤的过滤器，它可以根据指定的字段是否存在来匹配文档。例如： 1GET /myindex/_search &#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; &quot;exists&quot;: &#123; &quot;field&quot;: &quot;category&quot; &#125; &#125; &#125; &#125; &#125; 这个请求将按照category字段是否存在来过滤搜索结果。 Bool Filter Bool Filter是一种将多个过滤器组合起来进行过滤的过滤器，它可以将多个过滤器组合成AND、OR、NOT等逻辑关系来匹配文档。例如： 1GET /myindex/_search &#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: [ &#123; &quot;term&quot;: &#123; &quot;category&quot;: &quot;books&quot; &#125; &#125;, &#123; &quot;range&quot;: &#123; &quot;price&quot;: &#123; &quot;gte&quot;: 10, &quot;lt&quot;: 50 &#125; &#125; &#125; ] &#125; &#125; &#125; 这个请求将按照category字段的值为books和price字段的值在10和50之间来过滤搜索结果。 除了以上常见的过滤器类型，Elasticsearch还支持其他类型的过滤器，如Geo Distance Filter、Nested Filter、Script Filter等，可以根据实际需求选择合适的过滤器类型。 18、什么是Bulk API？它有什么作用？ Bulk API是Elasticsearch提供的一种用于批量操作的API，它可以一次性执行多个索引、更新、删除等操作，从而提高数据处理的效率。Bulk API使用JSON格式的请求体来描述多个操作，可以减少网络通信、提高吞吐量、降低延迟等，适用于大批量的数据处理场景。 Bulk API的请求体由多个操作组成，每个操作包括一个操作类型（index、update、delete等）、一个可选的操作元数据（index、type、id等）和一个文档内容。例如： 1POST /myindex/_bulk &#123;&quot;index&quot;:&#123;&quot;_id&quot;:&quot;1&quot;&#125;&#125; &#123;&quot;title&quot;:&quot;My first blog post&quot;,&quot;content&quot;:&quot;This is my first blog post.&quot;&#125; &#123;&quot;update&quot;:&#123;&quot;_id&quot;:&quot;2&quot;&#125;&#125; &#123;&quot;doc&quot;:&#123;&quot;content&quot;:&quot;This is my updated blog post.&quot;&#125;&#125; &#123;&quot;delete&quot;:&#123;&quot;_id&quot;:&quot;3&quot;&#125;&#125; 这个请求体包括三个操作：一个index操作、一个update操作和一个delete操作。index操作将一个新文档插入到myindex索引中；update操作将_id为2的文档的content字段更新为&quot;This is my updated blog post.&quot;；delete操作将_id为3的文档从索引中删除。 Bulk API的作用主要有以下几点： 提高数据处理效率 Bulk API可以一次性执行多个操作，减少网络通信和请求处理的开销，从而提高数据处理的效率和吞吐量。 降低网络延迟 Bulk API将多个操作合并到一起，可以降低网络延迟和请求响应时间，提高用户体验和系统性能。 简化代码实现 Bulk API可以简化代码实现，减少请求和响应的代码量，降低代码的复杂度和出错率。 需要注意的是，Bulk API虽然可以提高数据处理的效率，但是也会带来一些风险和限制。例如，Bulk API一次最多只能处理10MB的数据，否则可能会导致请求失败或性能下降；另外，Bulk API的操作是无序的，需要保证操作之间的依赖关系和正确性，否则可能会导致数据错误或数据不一致等问题。因此，在使用Bulk API时需要仔细考虑业务需求和实际情况，避免不必要的风险和限制。 19、Elasticsearch中的索引别名(Alias)是什么？如何创建一个索引别名？ 在Elasticsearch中，索引别名（Alias）是对一个或多个索引的命名引用，它可以让用户在执行搜索和其他操作时使用别名来代替实际的索引名称。索引别名的主要作用是提供一个简单的方式来处理索引的版本控制、数据迁移、数据备份等场景，并且可以提供更灵活的搜索和数据管理方式。例如，可以将别名用于分片和负载均衡、跨索引搜索、快速切换索引版本等。 创建一个索引别名可以通过以下步骤完成： 创建或选择一个已有的索引 首先需要创建或选择一个已有的索引，将它作为别名的目标索引。例如，假设我们已经有一个名为myindex的索引。 创建一个别名 接下来可以创建一个别名，将它指向目标索引。例如： 1POST /_aliases &#123; &quot;actions&quot; : [ &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;myindex&quot;, &quot;alias&quot; : &quot;myalias&quot; &#125; &#125; ] &#125; 这个请求将创建一个名为myalias的别名，将它指向myindex索引。注意，一个索引可以有多个别名，但一个别名只能指向一个索引。 执行操作 创建完别名后，就可以使用别名执行搜索和其他操作了。例如： 1GET /myalias/_search &#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;Elasticsearch&quot; &#125; &#125; &#125; 这个请求将使用myalias别名来搜索数据，实际上等同于对myindex索引执行同样的搜索操作。 需要注意的是，别名是一个动态的概念，可以随时添加、删除、修改。例如，可以通过remove操作删除一个别名，通过add操作添加一个别名，通过update操作修改一个别名的指向等。别名的创建和管理可以通过API和命令行工具完成，如curl命令、Kibana界面等。 20、什么是River？它有什么作用？ River是Elasticsearch中的一种插件，用于实现数据的实时同步和索引。它可以从外部数据源（如关系型数据库、NoSQL数据库、文件系统等）获取数据并将数据同步到Elasticsearch中的索引中，从而实现数据的实时索引和搜索。River插件的主要作用是简化数据同步和索引的过程，减少代码实现的复杂度和出错率，提高数据处理的效率和性能。 River插件的原理是通过轮询或监听外部数据源，获取最新的数据并将数据写入到Elasticsearch中。例如，可以通过JDBC River插件从关系型数据库中获取数据并写入到Elasticsearch中，也可以通过FileSystem River插件从文件系统中获取数据并写入到Elasticsearch中。River插件支持数据的增量同步和全量同步，可以根据实际需求选择合适的同步方式。 River插件已经在Elasticsearch 5.x版本中被弃用，取而代之的是Logstash等外部数据处理工具。这是因为River插件本身存在一些性能和稳定性问题，不适合用于生产环境的数据处理。因此，在使用River插件时需要谨慎考虑，避免不必要的风险和限制。 21、如何处理Elasticsearch的性能问题？ 处理Elasticsearch的性能问题需要从多个方面入手，包括硬件、索引设计、查询优化、缓存、负载均衡等方面。下面是一些处理Elasticsearch性能问题的常见方法： 硬件优化 硬件是影响Elasticsearch性能的一个重要因素，因此需要根据实际需求和数据量选择合适的硬件配置，如CPU、内存、磁盘等。同时，可以通过使用SSD硬盘、增加节点数、提高网络带宽等方式来提高硬件性能。 索引设计优化 索引是影响Elasticsearch性能的另一个重要因素，因此需要对索引进行优化。例如，可以选择合适的分片和副本数量、减少字段数量、使用合适的数据类型、使用合适的分词器和过滤器等方式来优化索引设计。 查询优化 查询是Elasticsearch性能的一个关键因素，因此需要对查询进行优化。例如，可以使用合适的查询语句、合理使用缓存、使用合适的过滤器、避免使用复杂的查询语句等方式来优化查询性能。 缓存优化 缓存是提高Elasticsearch性能的一个重要手段，可以通过使用合适的缓存策略、设置合适的缓存大小、选择合适的缓存类型等方式来优化缓存性能。 负载均衡优化 负载均衡是保证Elasticsearch性能的一个重要手段，可以通过使用合适的负载均衡策略、设置合适的节点数、选择合适的硬件配置等方式来优化负载均衡性能。 监控和调优 监控和调优是保证Elasticsearch性能的一个重要手段，可以通过使用合适的监控工具、定期进行性能分析、进行系统调优等方式来优化性能。 需要注意的是，Elasticsearch性能问题是一个复杂的问题，需要根据实际情况和需求进行综合优化。处理性能问题需要综合考虑硬件、索引、查询、缓存、负载均衡等多个方面的因素，并且需要不断地进行监控和调优，才能保证系统的稳定性和性能优化。 22、如何处理Elasticsearch的数据备份和恢复？ 在Elasticsearch中，数据备份和恢复是保证数据安全和可靠性的必要手段。数据备份可以帮助用户在数据丢失或系统故障时快速恢复数据，而数据恢复可以用于将备份数据还原到Elasticsearch中。下面是一些处理Elasticsearch数据备份和恢复的常见方法： 使用Snapshot和Restore Elasticsearch提供了Snapshot和Restore API，可以用于备份和恢复数据。Snapshot和Restore API可以将索引和数据保存到远程存储库中，并且可以根据需要进行全量或增量备份和恢复。使用Snapshot和Restore API需要先设置一个远程存储库，并且需要对索引进行关闭操作才能进行备份。 例如，创建一个远程存储库可以使用以下命令： 1PUT _snapshot/my_backup &#123; &quot;type&quot;: &quot;s3&quot;, &quot;settings&quot;: &#123; &quot;bucket&quot;: &quot;my_bucket&quot;, &quot;region&quot;: &quot;us-east-1&quot; &#125; &#125; 这个命令将创建一个名为my_backup的远程存储库，类型为s3，存储在名为my_bucket的S3存储桶中，存储区域为us-east-1。 备份一个索引可以使用以下命令： 1PUT /_snapshot/my_backup/snapshot_1?wait_for_completion=true &#123; &quot;indices&quot;: &quot;my_index&quot; &#125; 这个命令将备份名为my_index的索引到名为snapshot_1的快照中。 恢复一个索引可以使用以下命令： 1POST /_snapshot/my_backup/snapshot_1/_restore &#123; &quot;indices&quot;: &quot;my_index&quot;, &quot;ignore_unavailable&quot;: true, &quot;include_global_state&quot;: false &#125; 这个命令将从名为snapshot_1的快照中恢复名为my_index的索引。 使用第三方工具 除了使用Snapshot和Restore API外，还可以使用一些第三方工具来进行数据备份和恢复。例如，可以使用Elasticsearch Curator、Elasticsearch Backup等工具来进行备份和恢复操作。这些工具可以提供更多的功能和选项，如增量备份、压缩备份、定时备份等。 需要注意的是，数据备份和恢复是保证数据安全和可靠性的重要手段，需要根据实际需求和业务情况进行综合考虑。备份数据需要选择合适的存储类型和存储位置，并且需要定期进行备份操作；恢复数据需要仔细考虑数据版本和数据完整性，并且需要进行测试和验证，以保证数据恢复的正确性和可靠性。 23、Elasticsearch数据怎么和MySQL保持一致 将Elasticsearch数据与MySQL保持一致需要进行数据同步，通常可以采用以下两种方法： 使用Logstash Logstash是Elasticsearch官方提供的一个数据处理工具，可以用于将MySQL中的数据同步到Elasticsearch中。Logstash支持多种数据源和数据同步方式，例如使用JDBC输入插件从MySQL中读取数据，使用Elasticsearch输出插件将数据写入到Elasticsearch中。 例如，可以使用以下Logstash配置文件将MySQL中的数据同步到Elasticsearch中： 1input &#123; jdbc &#123; jdbc_connection_string =&gt; &quot;jdbc:mysql://localhost:3306/mydatabase&quot; jdbc_user =&gt; &quot;myuser&quot; jdbc_password =&gt; &quot;mypassword&quot; jdbc_driver_library =&gt; &quot;/path/to/mysql-connector-java.jar&quot; jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot; statement =&gt; &quot;SELECT * from mytable&quot; &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; [&quot;localhost:9200&quot;] index =&gt; &quot;myindex&quot; document_type =&gt; &quot;mytype&quot; document_id =&gt; &quot;%&#123;id&#125;&quot; &#125; &#125; 这个配置文件将从MySQL的mydatabase库中读取mytable表的数据，使用Elasticsearch的myindex索引和mytype类型进行索引，并且使用id字段作为文档ID。 使用Elasticsearch JDBC River插件 Elasticsearch JDBC River插件可以将MySQL中的数据同步到Elasticsearch中，类似于Logstash。JDBC River插件的原理是通过轮询或监听MySQL数据库，获取最新的数据并将数据写入到Elasticsearch中。JDBC River插件需要将插件安装到Elasticsearch中，并且配置MySQL的JDBC驱动程序和JDBC URL等参数。 例如，可以使用以下方式安装JDBC River插件： 1bin/plugin install jdbc-river 安装完成后，可以使用以下方式创建一个JDBC River： 1PUT _river/my_jdbc_river/_meta &#123; &quot;type&quot; : &quot;jdbc&quot;, &quot;jdbc&quot; : &#123; &quot;driver&quot; : &quot;com.mysql.jdbc.Driver&quot;, &quot;url&quot; : &quot;jdbc:mysql://localhost:3306/mydatabase&quot;, &quot;user&quot; : &quot;myuser&quot;, &quot;password&quot; : &quot;mypassword&quot;, &quot;sql&quot; : [ &#123; &quot;statement&quot; : &quot;SELECT * from mytable&quot; &#125; ], &quot;index&quot; : &#123; &quot;index&quot; : &quot;myindex&quot;, &quot;type&quot; : &quot;mytype&quot;, &quot;bulk_size&quot; : 100, &quot;bulk_timeout&quot; : &quot;10s&quot; &#125; &#125; &#125; 这个请求将创建一个名为my_jdbc_river的JDBC River，将MySQL的mydatabase库中的mytable表的数据同步到Elasticsearch的myindex索引中的mytype类型中，批量处理100条数据，每批数据处理的超时时间为10秒。 需要注意的是，Logstash和JDBC River都可以用于将MySQL中的数据同步到Elasticsearch中，但是它们的稳定性和性能存在一定的差异。因此，在使用这些工具时需要根据实际情况进行选择，并且需要进行测试和验证，以确保数据同步的正确性和可靠性。 var first_sceen__time = (+new Date()); if (“” == 1 &amp;&amp; document.getElementById(‘js_content’)) { document.getElementById(‘js_content’).addEventListener(“selectstart”,function(e){ e.preventDefault(); }); } 预览时标签不可点","categories":[{"name":"中间件","slug":"中间件","permalink":"https://marklinglon.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"elastic","slug":"elastic","permalink":"https://marklinglon.github.io/tags/elastic/"}]},{"title":"hexo部署使用","slug":"工具/hexo","date":"2021-01-20T16:00:00.000Z","updated":"2024-02-01T09:22:42.728Z","comments":true,"path":"2021/01/21/工具/hexo/","link":"","permalink":"https://marklinglon.github.io/2021/01/21/%E5%B7%A5%E5%85%B7/hexo/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. 部署过程参考链接 123https://blog.cofess.com/2017/11/01/hexo-blog-theme-pure-usage-description.html // 部署文档http://blog.iwwee.com/posts/hexo-optimize.html // 优化https://hexo.io/zh-cn/docs/syntax-highlight.html // 代码高亮 create article in dir source/_posts 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server Deploy to remote sites 1$ hexo clean ;hexo generate;hexo deploy","categories":[{"name":"工具","slug":"工具","permalink":"https://marklinglon.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://marklinglon.github.io/tags/hexo/"}]},{"title":"Java 内存","slug":"语言/java-memory","date":"2021-01-20T16:00:00.000Z","updated":"2024-02-01T09:23:19.983Z","comments":true,"path":"2021/01/21/语言/java-memory/","link":"","permalink":"https://marklinglon.github.io/2021/01/21/%E8%AF%AD%E8%A8%80/java-memory/","excerpt":"","text":"一、引言 为什么 Java 进程的实际物理内存使用量比 -Xmx 指定的 Max Heap size 大？ 为什么 Java NMT 显示的 committed 内存值比RSS值小(或者大)？ 是否有办法能限制一个 Java 进程的内存使用么？ 怎么排查 Java 进程内存问题？ … 二、Linux 内存管理 2.1 Linux 内存概念解析 RSS(RES): Resident Set Size. 进程实际物理内存使用大小。 VIRT:Virtual memory used by the task, it includes all code, data and shared libraries plus pages that have been swapped out and pages that have been mapped but not used. 进程的虚拟内存使用，包括该进程的代码，数据段，共享lib 以及 swap 出磁盘的内存。一般情况下，不用特别关注该指标，VIRT并不意味着物理内存。（64-bit的操作系统，虚拟地址空间大小为128T，可近似认为&quot;无限&quot;；32-bit的操作系统，虚拟空间大小为2G） Buffer: 对磁盘数据的缓存，既可以用在写，也可以用在读。 Cache: 对文件数据的缓存，既可以用在写，也可以用在读。 2.2 Linux 内存分配 一般 Unix 系统中，用户态的程序通过malloc()调用申请内存。如果返回值是 NULL， 说明此时操作系统没有空闲内存。这种情况下，用户程序可以选择直接退出并打印异常信息或尝试进行 GC 回收内存。然而 Linux 系统总会先满足用户程序malloc请求，并分配一片虚拟内存地址。只有在程序第一次touch到这片内存时，操作系统才会分配物理内存给进程。具体我们可以看下如下demo: 1.调用 malloc，但不touch： 12345678910111213#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main (void) &#123; int n = 0; while (1) &#123; if (malloc(1&lt;&lt;20) == NULL) &#123; printf(&quot;malloc failure after %d MiB\\n&quot;, n); return 0; &#125; printf (&quot;got %d MiB\\n&quot;, ++n); &#125;&#125; 调用 malloc，并touch： 1234567891011121314151617#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;int main (void) &#123; int n = 0; char *p; while (1) &#123; if ((p = malloc(1&lt;&lt;20)) == NULL) &#123; printf(&quot;malloc failure after %d MiB\\n&quot;, n); return 0; &#125; memset (p, 0, (1&lt;&lt;20)); printf (&quot;got %d MiB\\n&quot;, ++n); &#125;&#125; 其中 demo1 在malloc返回NULL前，将申请到很大的内存；demo2 在malloc返回NULL前，将申请到很小的内存。在一个内存8MiB的系统中，demo1 将申请到 274 MiB内存， demo2将申请到仅4MiB内存。 2.3 查看内存使用 free: 查看操作系统内存使用，包含目前的 Buffer，Cache 和 Swap 使用量 top: 查看进程内存，cpu使用等 /proc/[pid]/status: 该文件提供了进程的内存使用信息。VmPeak指，从进程启动到现在使用的虚拟内存最大值；VmSize指，当前该进程的虚拟内存使用量；VmHWM指，从进程启动到当前使用的物理内存最大值，对估计进程实际内存使用有很大帮助；VmRSS指，当前进程的物理内存使用量。例子如下： /proc/[pid]/mem: 通过该文件，可以像操作文件一样，操作进程的虚拟内存内容，如：读，写操作。可以直接修改这个文件的内容，来直接修改某个进程中的某个变量的内容。用一个简单的 Python 程序，我们就可以实现修改进程内存内容的”魔法“，具体可参考：https://blog.holbertonschool.com/hack-the-virtual-memory-c-strings-proc/ 。 /proc/[pid]/maps: 进程的虚拟内存地址分布 三、Java 进程内存分布 Native Memory Tracking 是Java7U40引入的HotSpot新特性，可以用于追踪 Java 进程内存使用，并可以通过jcmd命令来访问。NMT功能默认关闭，可以通过设置JVM参数 -XX:NativeMemoryTracking=[summary | detail]来打开。值得注意的是，NMT 只能Track JVM自身的内存分配，第三方的Native库内存使用无法Track；NMT 有5%-10%的性能开销。 上图是 NMT 的输出例子，可以看到NMT不仅能 Track 堆内存的内存使用，还能Track其他部分的内存使用，如：Class，Code，Compiler，Internal，Symbol等部分的内存使用。其中committed可以认为是物理内存使用，即RSS。下面将对各部分进行分析。 3.1 Heap Heap 是 Java 进程中使用量最大的一部分内存，是最常遇到内存问题的部分，Java 也提供了很多相关工具来排查堆内存泄露问题，这里不详细展开。Heap 与 RSS 相关的几个重要JVM 参数如下： Xms：Java Heap 初始内存大小。【不是最小的Heap size】 Xmx：Java Heap 的最大大小。 XX:+AlwaysPretouch:在JVM初始化时，是否直接对Heap部分内存进行”填零“。正如上文所说，进程启动的时候,虽然我们可以为JVM指定合适的内存大小,但是这些内存操作系统并没有真正的分配给JVM,而是等JVM访问这些内存的时候,才真正分配。通过配置这个参数JVM就会先访问所有分配给它的内存,让操作系统把内存真正的分配给JVM.从而提高运行时的性能，后续JVM就可以更好的访问内存了。 XX:+UseAdaptiveSizePolicy：是否开启自适应大小策略。开启后，JVM将动态判断是否调整Heap size，来降低系统负载。 3.2 Metaspace Metaspace 主要包含方法的字节码，Class对象，常量池。一般来说，记载的类越多，Metaspace 使用的内存越多。与Metaspace相关的JVM参数有: XX:MaxMetaspaceSize: 最大的Metaspace大小限制【默认无限制】 XX:MetaspaceSize=64M: 初始的Metaspace大小。如果Metaspace空间不足，将会触发Full gc，例子如下图： 3.3 Thread NMT 中显示的Thread 部分内存与线程数与-Xss参数成正比，一般来说committed内存等于Xss*线程数。下图中显示有38个线程，committed内存大约为38M，从这可以推断出该Java 进程的Xss参数值为1M。 然而比较幸运的是，NMT 中Thread 的committed内存，并不等于 Java 线程的实际内存使用，具体可以参考： https://stackoverflow.com/questions/31173374/why-does-a-jvm-report-more-committed-memory-than-the-linux-process-resident-set https://github.com/apangin/jstackmem/blob/master/jstackmem.py NMT 中Thread部分实际物理内存使用，大致可以用下图描述： 3.4 Code JIT 动态编译产生的Code占用的内存。这部分内存主要由-XX:ReservedCodeCacheSize参数进行控制，默认是：240M。可以通过关闭分层编译-XX:-TieredCompilation来减低Code Cache部分的内存使用。另外，-XX:+PrintCodeCache参数，可以打印出Code Cache相关的详细信息，帮助我们定位内存泄露问题，打印信息如下： 3.5 Internal Internal 部分内存主要是java.nio.DirectByteBuffer对象占用。java.nio.DirectByteBuffer是’冰山对象‘，Heap中有堆外内存的引用,heap内的引用对象内存占用很小，实际的内存使用不在heap上，而是通过Unsafe.allocate进行分配的。查看java.nio.DirectByteBuffer的内存使用，有两个方法： 通过NMT输出日志，查看Internal部分的committed内存 和 Unsafe调用分配内存： MAT分析Heap中java.nio.Bits类中totalCapcity： 具体原理，可以参考之前的一个回答：https://www.zhihu.com/question/58943470/answer/1130876729 3.6 Symbol Symbol 部分主要有两部分： SymbolTable: names signatures StringTable: interned strings可以通过-XX:+PrintStringTableStatistics打印具体的信息，输入大致如下： 3.7 小结 1、为什么 Java 进程的实际物理内存使用量比 -Xmx 指定的 Max Heap size 大？ 答：有堆外内存，如：Code，Metaspace，Class，Thread，Internal等其他的内存消耗部分。 2、为什么 Java NMT 显示的 committed 内存值比RSS值小(或者大)？ 答：一般情况下NMT Track出来的 committed 内存值既可能比RSS值大，也可能比RSS小，主要原因是： 比真实RSS小：NMT 只能Track JVM自身的内存分配情况，比如：Heap内存分配，direct byte buffer等；不能 Track jni里直接调用malloc时的内存分配，这里最典型的就是ZipInputStream的场景。 比真实RSS大：NMT 中关于Thread的部分的 committed 部分内存，基本等于-Xss值 * Thread数量，并没有反映Java Thread Stack真实对应到RSS的内存值。（可能是JVM的bug？）考虑到操作系统内存的懒加载机制，单个Thread Stack实际RSS使用基本在100k左右。详细信息可参考：https://stackoverflow.com/questions/31173374/why-does-a-jvm-report-more-committed-memory-than-the-linux-process-resident-set。简单的说，就是从NMT上看到的Thread committed内存是大于Thread的实际Rss值的。 3、是否有办法能限制一个 Java 进程的内存使用么？ 答：没有。Java 有很多无法限制的部分，如：Metaspace，Thread，第三方Native调用等。 四、怎么排查 4.1 大致流程 4.2 Java jmap: dump heap dump；分析heap jcmd: NMT 分析 jinfo：查看进程启动命令，确定各JVM参数的配置值 MAT: 分析Heap NMT: 分析具体Java 进程的各部分内存分布，包含堆外内存 … 4.3 系统级别 pmap：追踪“可疑”内存 strace：追踪系统调用 gdb: dump “可疑”内存内容，帮助分析内存泄露问题 五、Example https://zhuanlan.zhihu.com/p/54048271 https://zhuanlan.zhihu.com/p/60976273 六、参考 Difference with Linux VmRSS and the total commited memory of Java NativeMemoryTraking (NMT)：https://stackoverflow.com/questions/58430156/difference-with-linux-vmrss-and-the-total-commited-memory-of-java-nativememorytr 如何用async-profiler profile 堆外内存：https://stackoverflow.com/questions/53576163/interpreting-jemaloc-data-possible-off-heap-leak/53598622#53598622 Memory Footprint of A Java Process: https://vimeo.com/364039638 Why does a JVM report more committed memory than the linux process resident set size?: https://stackoverflow.com/questions/31173374/why-does-a-jvm-report-more-committed-memory-than-the-linux-process-resident-set","categories":[{"name":"语言","slug":"语言","permalink":"https://marklinglon.github.io/categories/%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"java","slug":"java","permalink":"https://marklinglon.github.io/tags/java/"}]},{"title":"Kubebuilder Watch Rresources","slug":"k8s/kubebuilder-watch-resources","date":"2020-06-20T16:00:00.000Z","updated":"2024-02-01T09:24:19.281Z","comments":true,"path":"2020/06/21/k8s/kubebuilder-watch-resources/","link":"","permalink":"https://marklinglon.github.io/2020/06/21/k8s/kubebuilder-watch-resources/","excerpt":"","text":"我们在开发过程中，可能需要开发一个类似Deployment的资源逻辑，管理依赖资源是控制器的基础，如果不能观察它们的状态变化就不可能管理它们。这就意味着，我们需要 reconciler 能监控多个资源的变化。 NOTE: Deployment 必须知道其管理的 ReplicaSet 何时更改，ReplicaSet 必须知道其管理的 Pod 何时被删除，或者从健康变为不健康等。 控制器运行时库为管理和监视资源提供了多种方式。这包括从简单而明显的用例（例如查看由控制器创建和管理的资源）到更独特和更高级的用例。 •控制器创建和管理的资源 (Watching Operator Managed Resources) •外部管理的资源 (Watching Externally Managed Resources) 背景 以 Tcaplus 资源为例，Tcaplus 资源通过 ConfigMap（proto 文件）来创建表格。当 ConfigMap 发生变化时自动更新表格，下面例子不实际调用腾讯云API，只要验证接收到事件请求即可。 NOTE: TcaplusDB 是腾讯出品的分布式NoSQL数据库。官方API文档：https://cloud.tencent.com/document/product/596/39648。 控制器创建和管理的资源 资源定义 (Defined Tcaplus Resources) api/v1/tcaplus_types.go 123456789type TcaplusSpec struct &#123; Checksum string `json:&quot;checksum,omitempty&quot;` ConfigMapTemplate ConfigMapTemplate `json:&quot;configMapTemplate,omitempty&quot;`&#125;type ConfigMapTemplate struct &#123; Name string `json:&quot;name,omitempty&quot;` Data map[string]string `json:&quot;data,omitempty&quot;`&#125; 控制器逻辑 (Manage the Owned Resource) controllers/tcaplus_controller.go 当 tcaplus CR 创建时根据 ConfigMapTemplate 创建附属的 ConfigMap 资源并设置属主关系。 •Reconcile 方法：根据模版创建 ConfigMap 并设置属主关系 •SetupWithManager 方法：For 方法之后调用 Owns 方法 1234567891011121314151617181920212223242526272829303132333435func (r *TcaplusReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) &#123; logger := log.FromContext(ctx) logger.Info(&quot;reconciling&quot;) tcaplus := &amp;examplev1.Tcaplus&#123;&#125; if err := r.Get(ctx, req.NamespacedName, tcaplus); err != nil &#123; return ctrl.Result&#123;&#125;, client.IgnoreNotFound(err) &#125; configMap := &amp;corev1.ConfigMap&#123;&#125; configMap.Name = tcaplus.Spec.ConfigMapTemplate.Name configMap.Namespace = tcaplus.Namespace configMap.Data = tcaplus.Spec.ConfigMapTemplate.Data if err := controllerutil.SetControllerReference(tcaplus, configMap, r.Scheme); err != nil &#123; logger.Error(err, &quot;get configmap failed&quot;, &quot;configmap&quot;, configMap.Name) return ctrl.Result&#123;&#125;, err &#125; foundConfigMap := &amp;corev1.ConfigMap&#123;&#125; err := r.Get(ctx, types.NamespacedName&#123;Name: configMap.Name, Namespace: tcaplus.Namespace&#125;, foundConfigMap) if err != nil &amp;&amp; errors.IsNotFound(err) &#123; logger.V(1).Info(&quot;creating configmap&quot;, &quot;configmap&quot;, configMap.Name) err = r.Create(ctx, configMap) &#125; return ctrl.Result&#123;&#125;, nil&#125;// SetupWithManager sets up the controller with the Manager.func (r *TcaplusReconciler) SetupWithManager(mgr ctrl.Manager) error &#123; return ctrl.NewControllerManagedBy(mgr). For(&amp;examplev1.Tcaplus&#123;&#125;). Owns(&amp;corev1.ConfigMap&#123;&#125;). Complete(r)&#125; NOTE：同一控制器创建的资源才可以设置属主关系，不然会提示：already owned by another controller。 测试 config/samples/example_v1_tcaplus.yaml 1234567891011121314151617apiVersion: example.blazehu.com/v1kind: Tcaplusmetadata: name: tcaplus-samplespec: checksum: &quot;123&quot; configMapTemplate: name: &quot;tcaplus-configmap-example&quot; data: demo.proto: | syntax = &quot;proto3&quot;; package example; message Example &#123; uint32 a = 1; uint32 b = 2; uint32 c = 3; &#125; 使用上述配置文件创建 tcaplus 资源。创建结果： 123456marklu-MB2:samples $ k get tcaplusNAME AGEtcaplus-sample 19mmarklu-MB2:samples $ k get configmapNAME DATA AGEtcaplus-configmap-example 1 19m 可以查看 tcaplus-configmap-example 的属主关系： 123456789101112131415161718192021222324apiVersion: v1data: demo.proto: | syntax = &quot;proto3&quot;; package example; message Example &#123; uint32 a = 1; uint32 b = 2; &#125;kind: ConfigMapmetadata: creationTimestamp: &quot;2022-07-07T09:02:43Z&quot; name: tcaplus-configmap-example namespace: default ownerReferences: - apiVersion: example.blazehu.com/v1 blockOwnerDeletion: true controller: true kind: Tcaplus name: tcaplus-sample uid: 7c50f2e1-0e37-4aa0-bf49-c2d410d6153e resourceVersion: &quot;6837330713&quot; selfLink: /api/v1/namespaces/default/configmaps/tcaplus-configmap-example uid: 6c29f90b-0e51-4d9f-a6a8-cfb6906ed1b0 手动修改 tcaplus-sample 和 tcaplus-configmap-example 后查看控制器日志发现能正常观察 CR 和 ConfigMap 的变化了。 外部管理的资源 资源定义 (Defined Tcaplus Resources) api/v1/tcaplus_types.go 12345678type TcaplusSpec struct &#123; Checksum string `json:&quot;checksum,omitempty&quot;` ConfigMapRef ConfigMapReference `json:&quot;configMapRef,omitempty&quot;`&#125;type ConfigMapReference struct &#123; Name string `json:&quot;name,omitempty&quot;`&#125; 控制器逻辑 (Manage the Owned Resource) controllers/tcaplus_controller.go For 方法之后调用 Watches 方法就可以监听对应资源的事件，但是会监听集群里所有相关资源的事件，所以这里我们自定义事件处理方法来过滤出我们关注的资源的事件。 •通过 EnqueueRequestsFromMapFunc 创建一个事件处理方法，该方法通过 FieldSelector 在 ConfigMap 的事件中过滤出跟 tcaplus CR 相关联的事件。 •使用 FieldSelector 时我们需要建立对应的索引，使用 mgr.GetFieldIndexer().IndexField() 创建。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546const ( ConfigMapField = &quot;.spec.configMapRef.name&quot;) func (r *TcaplusReconciler) findObjectsForConfigMap(configMap client.Object) []reconcile.Request &#123; attachedTcaplusList := &amp;examplev1.TcaplusList&#123;&#125; listOps := &amp;client.ListOptions&#123; FieldSelector: fields.OneTermEqualSelector(ConfigMapField, configMap.GetName()), Namespace: configMap.GetNamespace(), &#125; err := r.List(context.TODO(), attachedTcaplusList, listOps) if err != nil &#123; return []reconcile.Request&#123;&#125; &#125; requests := make([]reconcile.Request, len(attachedTcaplusList.Items)) for i, item := range attachedTcaplusList.Items &#123; requests[i] = reconcile.Request&#123; NamespacedName: types.NamespacedName&#123; Name: item.GetName(), Namespace: item.GetNamespace(), &#125;, &#125; &#125; return requests&#125; // SetupWithManager sets up the controller with the Manager.func (r *TcaplusReconciler) SetupWithManager(mgr ctrl.Manager) error &#123; if err := mgr.GetFieldIndexer().IndexField(context.Background(), &amp;examplev1.Tcaplus&#123;&#125;, ConfigMapField, func(rawObj client.Object) []string &#123; tcaplus := rawObj.(*examplev1.Tcaplus) if tcaplus.Spec.ConfigMapRef.Name == &quot;&quot; &#123; return nil &#125; return []string&#123;tcaplus.Spec.ConfigMapRef.Name&#125; &#125;); err != nil &#123; return err &#125; return ctrl.NewControllerManagedBy(mgr). For(&amp;examplev1.Tcaplus&#123;&#125;). Watches( &amp;source.Kind&#123;Type: &amp;corev1.ConfigMap&#123;&#125;&#125;, handler.EnqueueRequestsFromMapFunc(r.findObjectsForConfigMap), builder.WithPredicates(predicate.ResourceVersionChangedPredicate&#123;&#125;), ). Complete(r)&#125; NOTE: 我们也可以自己定一个变更过滤器 Predicate。也可以通过 WithEventFilter 来针对监听的所有资源过滤。 测试 config/samples/example_v1_tcaplus.yaml 1234567891011121314151617181920212223apiVersion: v1kind: ConfigMapmetadata: name: tcaplus-configmap-exampledata: demo.proto: | syntax = &quot;proto3&quot;; package example; message Example &#123; uint32 a = 1; uint32 b = 2; uint32 c = 3; &#125;---apiVersion: example.blazehu.com/v1kind: Tcaplusmetadata: name: tcaplus-samplespec: checksum: &quot;123&quot; configMapRef: name: &quot;tcaplus-configmap-example&quot; 使用上述配置创建完毕后，手动修改 tcaplus-sample 和 tcaplus-configmap-example 查看控制器日志发现同样能正常观察 CR 和 ConfigMap 的变化。 NOTE: 查看 tcaplus-configmap-example 可以看到没有和 tcaplus 的属主关系。 总结 •EventHandler 可以在 watch 特定资源时设置该资源的事件监听规则。 •WithEventFilter 配置变更过滤器，可以针对 watch 的所有资源，统一地设置事件监听规则。 •Owns 源码分析可以发现 Owns 相当于调用 Watches(&amp;source.Kind{Type: }, &amp;handler.EnqueueRequestForOwner{OwnerType: apiType, IsController: true})。 参考文档 •https://www.kubebuilder.io/reference/watching-resources.html •https://kubernetes.io/zh-cn/docs/concepts/overview/working-with-objects/owners-dependents/ •https://segmentfault.com/a/1190000020359577","categories":[{"name":"K8s","slug":"K8s","permalink":"https://marklinglon.github.io/categories/K8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://marklinglon.github.io/tags/k8s/"}]},{"title":"Kubebuilder Best Practices","slug":"k8s/kubebuilder-best-practices","date":"2020-06-20T16:00:00.000Z","updated":"2024-02-01T09:24:14.979Z","comments":true,"path":"2020/06/21/k8s/kubebuilder-best-practices/","link":"","permalink":"https://marklinglon.github.io/2020/06/21/k8s/kubebuilder-best-practices/","excerpt":"","text":"Kubebuilder is a framework for building Kubernetes APIs using custom resource definitions (CRDs). Note: kubebuilder can save us a lot of work and make developing CRDs and adminsion webhooks incredibly easy. Installation 123# download kubebuilder and install locally.curl -L -o kubebuilder https://go.kubebuilder.io/dl/latest/$(go env GOOS)/$(go env GOARCH)chmod +x kubebuilder &amp;&amp; mv kubebuilder /usr/local/bin/ Create a Project Create a directory, and then run the init command inside of it to initialize a new project. Follows an example. 1234567891011[marklu@MacBook ~]$ mkdir ~/Project/workspace-go/example[marklu@MacBook ~]$ cd ~/Project/workspace-go/example[marklu@MacBook ~]$ kubebuilder init --domain marklu.com --owner &quot;marklu&quot; --repo marklu.com/exampleWriting kustomize manifests for you to edit...Writing scaffold for you to edit...Get controller runtime:$ go get sigs.k8s.io/controller-runtime@v0.10.0Update dependencies:$ go mod tidyNext: define a resource with:$ kubebuilder create api If your project is initialized within GOPATH, the implicitly called go mod init will interpolate the module path for you. Otherwise –repo=must be set. Adding a new API 12345678910111213141516171819[marklu@MacBook ~]$ kubebuilder create api --group cos --version v1 --kind BucketCreate Resource [y/n]yCreate Controller [y/n]yWriting kustomize manifests for you to edit...Writing scaffold for you to edit...api/v1/bucket_types.gocontrollers/bucket_controller.goUpdate dependencies:$ go mod tidyRunning make:$ make generatego: creating new go.mod: module tmpDownloading sigs.k8s.io/controller-tools/cmd/controller-gen@v0.7.0go get: added sigs.k8s.io/controller-tools v0.7.0/Users/huyuhan/Project/workspace-go/example/bin/controller-gen object:headerFile=&quot;hack/boilerplate.go.txt&quot; paths=&quot;./...&quot;Next: implement your new API and generate the manifests (e.g. CRDs,CRs) with:$ make manifests Designing an API api/v1/bucket_types.go 12345678910// BucketSpec defines the desired state of Buckettype BucketSpec struct &#123; // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster // Important: Run &quot;make&quot; to regenerate code after modifying this file // Foo is an example field of Bucket. Edit bucket_types.go to remove/update Name string `json:&quot;name,omitempty&quot;` Region string `json:&quot;region,omitempty&quot;` ACL string `json:&quot;acl,omitempty&quot;`&#125; Implementing a controller controllers/cos.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package controllersimport ( &quot;context&quot; &quot;fmt&quot; &quot;github.com/tencentyun/cos-go-sdk-v5&quot; &quot;net/http&quot; &quot;net/url&quot;)type CosStorage struct &#123; client *cos.Client accessKeyId string accessKeySecret string bucket string region string&#125;// NewCosStorage endpoint: https://cloud.tencent.com/document/product/436/6224func NewCosStorage(region, bucketName string) *CosStorage &#123; url, _ := url.Parse(fmt.Sprintf(&quot;https://%s.cos.%s.myqcloud.com&quot;, bucketName, region)) accessKeyId := &quot;&quot; accessKeySecret := &quot;&quot; b := &amp;cos.BaseURL&#123;BucketURL: url&#125; client := cos.NewClient(b, &amp;http.Client&#123; Transport: &amp;cos.AuthorizationTransport&#123; SecretID: accessKeyId, SecretKey: accessKeySecret, &#125;, &#125;) return &amp;CosStorage&#123; client: client, accessKeyId: accessKeyId, accessKeySecret: accessKeySecret, region: region, bucket: bucketName, &#125;&#125;func (c *CosStorage) Put(acl string) error &#123; opt := &amp;cos.BucketPutOptions&#123; XCosACL: acl, &#125; _, err := c.client.Bucket.Put(context.Background(), opt) return err&#125;func (c *CosStorage) Delete() error &#123; _, err := c.client.Bucket.Delete(context.Background()) return err&#125; controllers/bucket_controller.go tips: Finalizers allow controllers to implement asynchronous pre-delete hooks. Let’s say you create an external resource (such as a storage bucket) for each object of your API type, and you want to delete the associated external resource on object’s deletion from Kubernetes, you can use a finalizer to do that. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120/*Copyright 2022 marklu.Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);you may not use this file except in compliance with the License.You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an &quot;AS IS&quot; BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.*/package controllersimport ( &quot;context&quot; &quot;k8s.io/apimachinery/pkg/runtime&quot; ctrl &quot;sigs.k8s.io/controller-runtime&quot; &quot;sigs.k8s.io/controller-runtime/pkg/client&quot; &quot;sigs.k8s.io/controller-runtime/pkg/controller/controllerutil&quot; &quot;sigs.k8s.io/controller-runtime/pkg/log&quot; cosv1 &quot;marklu.com/example/api/v1&quot;)// BucketReconciler reconciles a Bucket objecttype BucketReconciler struct &#123; client.Client Scheme *runtime.Scheme&#125;const ( bucketFinalizerName = &quot;bucket.cos.marklu.com/finalizer&quot;)//+kubebuilder:rbac:groups=cos.marklu.com,resources=buckets,verbs=get;list;watch;create;update;patch;delete//+kubebuilder:rbac:groups=cos.marklu.com,resources=buckets/status,verbs=get;update;patch//+kubebuilder:rbac:groups=cos.marklu.com,resources=buckets/finalizers,verbs=update// Reconcile is part of the main kubernetes reconciliation loop which aims to// move the current state of the cluster closer to the desired state.// TODO(user): Modify the Reconcile function to compare the state specified by// the Bucket object against the actual cluster state, and then// perform operations to make the cluster state reflect the state specified by// the user.//// For more details, check Reconcile and its Result here:// - https://pkg.go.dev/sigs.k8s.io/controller-runtime@v0.10.0/pkg/reconcilefunc (r *BucketReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) &#123; logger := log.FromContext(ctx) bucket := &amp;cosv1.Bucket&#123;&#125; if err := r.Get(ctx, req.NamespacedName, bucket); err != nil &#123; return ctrl.Result&#123;&#125;, client.IgnoreNotFound(err) &#125; // examine DeletionTimestamp to determine if object is under deletion if bucket.ObjectMeta.DeletionTimestamp.IsZero() &#123; // The object is not being deleted, so if it does not have our finalizer, // then lets add the finalizer and update the object. This is equivalent // registering our finalizer. if !controllerutil.ContainsFinalizer(bucket, bucketFinalizerName) &#123; controllerutil.AddFinalizer(bucket, bucketFinalizerName) if err := r.Update(ctx, bucket); err != nil &#123; return ctrl.Result&#123;&#125;, err &#125; &#125; else &#123; if err := r.updateExternalResources(bucket); err != nil &#123; logger.Error(err, &quot;unable to create Bucket&quot;) return ctrl.Result&#123;&#125;, err &#125; logger.Info(&quot;create Bucket succeed&quot;) &#125; &#125; else &#123; // The object is being deleted if controllerutil.ContainsFinalizer(bucket, bucketFinalizerName) &#123; // our finalizer is present, so lets handle any external dependency if err := r.deleteExternalResources(bucket); err != nil &#123; // if fail to delete the external dependency here, return with error // so that it can be retried logger.Error(err, &quot;unable to delete Bucket&quot;) return ctrl.Result&#123;&#125;, err &#125; // remove our finalizer from the list and update it. controllerutil.RemoveFinalizer(bucket, bucketFinalizerName) if err := r.Update(ctx, bucket); err != nil &#123; return ctrl.Result&#123;&#125;, err &#125; logger.Info(&quot;delete Bucket succeed&quot;) &#125; // Stop reconciliation as the item is being deleted return ctrl.Result&#123;&#125;, nil &#125; // bucket reconcile logic return ctrl.Result&#123;&#125;, nil&#125;func (r *BucketReconciler) updateExternalResources(bucket *cosv1.Bucket) error &#123; cosClient := NewCosStorage(bucket.Spec.Region, bucket.Spec.Name) return cosClient.Put(bucket.Spec.ACL)&#125;func (r *BucketReconciler) deleteExternalResources(bucket *cosv1.Bucket) error &#123; cosClient := NewCosStorage(bucket.Spec.Region, bucket.Spec.Name) return cosClient.Delete()&#125;// SetupWithManager sets up the controller with the Manager.func (r *BucketReconciler) SetupWithManager(mgr ctrl.Manager) error &#123; return ctrl.NewControllerManagedBy(mgr). For(&amp;cosv1.Bucket&#123;&#125;). Complete(r)&#125; Test It Out Install the CRDs into the cluster (make install) 1234[marklu@MacBook ~]$ make install/Users/huyuhan/Project/workspace-go/example/bin/controller-gen rbac:roleName=manager-role crd webhook paths=&quot;./...&quot; output:crd:artifacts:config=config/crd/bases/Users/huyuhan/Project/workspace-go/example/bin/kustomize build config/crd | kubectl apply -f -customresourcedefinition.apiextensions.k8s.io/buckets.cos.marklu.com created Run your controller (this will run in the foreground, so switch to a new terminal if you want to leave it running) (make run) 123456789101112[marklu@MacBook ~]$ make run/Users/huyuhan/Project/workspace-go/example/bin/controller-gen rbac:roleName=manager-role crd webhook paths=&quot;./...&quot; output:crd:artifacts:config=config/crd/bases/Users/huyuhan/Project/workspace-go/example/bin/controller-gen object:headerFile=&quot;hack/boilerplate.go.txt&quot; paths=&quot;./...&quot;go fmt ./...go vet ./...go run ./main.go2022-01-27T22:05:30.207+0800 INFO controller-runtime.metrics metrics server is starting to listen &#123;&quot;addr&quot;: &quot;:8080&quot;&#125;2022-01-27T22:05:30.207+0800 INFO setup starting manager2022-01-27T22:05:30.208+0800 INFO starting metrics server &#123;&quot;path&quot;: &quot;/metrics&quot;&#125;2022-01-27T22:05:30.208+0800 INFO controller.bucket Starting EventSource &#123;&quot;reconciler group&quot;: &quot;cos.marklu.com&quot;, &quot;reconciler kind&quot;: &quot;Bucket&quot;, &quot;source&quot;: &quot;kind source: /, Kind=&quot;&#125;2022-01-27T22:05:30.208+0800 INFO controller.bucket Starting Controller &#123;&quot;reconciler group&quot;: &quot;cos.marklu.com&quot;, &quot;reconciler kind&quot;: &quot;Bucket&quot;&#125;2022-01-27T22:05:30.309+0800 INFO controller.bucket Starting workers &#123;&quot;reconciler group&quot;: &quot;cos.marklu.com&quot;, &quot;reconciler kind&quot;: &quot;Bucket&quot;, &quot;worker count&quot;: 1&#125; Create Custom Resources (create bucket.cos.marklu.com/bucket-sample) (cos_v1_bucket.yaml) 12345678910apiVersion: cos.marklu.com/v1kind: Bucketmetadata: name: bucket-sample namespace: markluspec: # TODO(user): Add fields here name: example-1251762279 region: ap-shanghai acl: private kubectl apply -f cos_v1_bucket.yaml 12345[marklu@MacBook ~]$ kubectl apply -f cos_v1_bucket.yamlbucket.cos.marklu.com/bucket-sample created[marklu@MacBook ~]$ kubectl get bucket.cos.marklu.com -n markluNAME AGEbucket-sample 17s Tencent cloud console view found that the bucket was created normally. Delete Instances of Custom Resources (delete bucket.cos.marklu.com/bucket-sample) 12[marklu@MacBook ~]$ kubectl delete -f cos_v1_bucket.yamlbucket.cos.marklu.com &quot;bucket-sample&quot; deleted Run It On the Cluster Deploy the controller to the cluster with image specified by IMG 12make docker-build docker-push IMG=&lt;some-registry&gt;/&lt;project-name&gt;:tagmake deploy IMG=&lt;some-registry&gt;/&lt;project-name&gt;:tag Reference documentation https://github.com/kubernetes-sigs/kubebuilder https://book.kubebuilder.io/introduction.html https://kubernetes.io/docs/concepts/extend-kubernetes/operator/","categories":[{"name":"K8s","slug":"K8s","permalink":"https://marklinglon.github.io/categories/K8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://marklinglon.github.io/tags/k8s/"}]},{"title":"Kubebuilder Admission Webhooks","slug":"k8s/kubebuilder-Admission-Webhooks","date":"2020-06-20T16:00:00.000Z","updated":"2024-02-01T09:24:09.487Z","comments":true,"path":"2020/06/21/k8s/kubebuilder-Admission-Webhooks/","link":"","permalink":"https://marklinglon.github.io/2020/06/21/k8s/kubebuilder-Admission-Webhooks/","excerpt":"","text":"什么是准入控制? 准入控制（Admission Controller）是 Kubernetes API Server 用于拦截请求的一种手段。Admission 可以做到对请求的资源对象进行校验，修改。service mesh 最近很火的项目 Istio 天生支持 Kubernetes，利用的就是 Admission 对服务实例自动注入 sidecar。 什么是准入 Webhook？ 准入 Webhook 是一种用于接收准入请求并对其进行处理的 HTTP 回调机制。 可以定义两种类型的准入 webhook，即 验证性质的准入 Webhook 和 修改性质的准入 Webhook。修改性质的准入 Webhook 会先被调用。它们可以更改发送到 API 服务器的对象以执行自定义的设置默认值操作。 在完成了所有对象修改并且 API 服务器也验证了所传入的对象之后， 验证性质的 Webhook 会被调用，并通过拒绝请求的方式来强制实施自定义的策略。 说明： 如果准入 Webhook 需要保证它们所看到的是对象的最终状态以实施某种策略。 则应使用验证性质的准入 Webhook，因为对象被修改性质 Webhook 看到之后仍然可能被修改。 尝试准入 Webhook 先决条件 •确保 Kubernetes 集群版本至少为 v1.16（以便使用 admissionregistration.k8s.io/v1 API） 或者 v1.9 （以便使 admissionregistration.k8s.io/v1beta1 API）。 •确保启用 MutatingAdmissionWebhook 和 ValidatingAdmissionWebhook 控制器。 这里是一组推荐的 admission 控制器，通常可以启用。 •确保启用了 admissionregistration.k8s.io/v1beta1 API。 配置准入 Webhook 你可以通过 ValidatingWebhookConfiguration 或者 MutatingWebhookConfiguration 动态配置哪些资源要被哪些准入 Webhook 处理。详细配置可以参阅 Webhook配置 部分。 认证和信任 默认情况下，apiserver不会向webhooks进行身份验证。但是，如果您想对客户端进行身份验证，可以将apiserver配置为使用基本身份验证、承载令牌或证书对Webhook进行身份验证。你可以在这里找到详细的步骤。 编写一个准入 Webhook 服务器 Webhook Admission 属于同步调用，需要用户部署自己的 webhook server，创建自定义的配置资源对象： ValidatingWebhookConfiguration 或 MutatingWebhookConfiguration。下面使用 kubebuilder 开发一个简单的 demo。 6.1 创建项目 1kubebuilder init --domain marklu.com --owner &quot;marklu&quot; --repo marklu.com/kubegame 提示： 这里通过 kubebuilder v3 创建的话，在 config 目录下会缺少 certmanager、webhook 目录以及 default/manager_webhook_patch.yml 和 webhookcainjection_patch.yaml 文件。可以通过从v2生成拷贝过来进行修改。 6.2 创建控制器 这里只需要创建一个控制器 1kubebuilder create api --group svc --version v1 --kind App 6.3 创建 webhook Implement Your Handler 新增 mutatingwebhook.go &amp; validatingwebhook.go 文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// mutatingwebhook.gopackage controllersimport ( &quot;context&quot; &quot;encoding/json&quot; corev1 &quot;k8s.io/api/core/v1&quot; &quot;net/http&quot; &quot;sigs.k8s.io/controller-runtime/pkg/client&quot; &quot;sigs.k8s.io/controller-runtime/pkg/webhook/admission&quot;)// +kubebuilder:webhook:admissionReviewVersions=v1,sideEffects=None,path=/mutate-v1-svc,mutating=true,failurePolicy=fail,groups=&quot;&quot;,resources=services,verbs=create;update,versions=v1,name=msvc.kb.io// KubeGameAnnotator annotates Podstype KubeGameAnnotator struct &#123; Client client.Client decoder *admission.Decoder&#125;// Handle adds an annotation to every incoming pods.func (a *KubeGameAnnotator) Handle(ctx context.Context, req admission.Request) admission.Response &#123; pod := &amp;corev1.Pod&#123;&#125; err := a.decoder.Decode(req, pod) if err != nil &#123; return admission.Errored(http.StatusBadRequest, err) &#125; if pod.Annotations == nil &#123; pod.Annotations = map[string]string&#123;&#125; &#125; pod.Annotations[&quot;example-mutating-admission-webhook&quot;] = &quot;foo&quot; marshaledPod, err := json.Marshal(pod) if err != nil &#123; return admission.Errored(http.StatusInternalServerError, err) &#125; return admission.PatchResponseFromRaw(req.Object.Raw, marshaledPod)&#125;// KubeGameAnnotator implements admission.DecoderInjector.// A decoder will be automatically injected.// InjectDecoder injects the decoder.func (a *KubeGameAnnotator) InjectDecoder(d *admission.Decoder) error &#123; a.decoder = d return nil&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// validatingwebhook.gopackage controllersimport ( &quot;context&quot; &quot;fmt&quot; corev1 &quot;k8s.io/api/core/v1&quot; &quot;net/http&quot; &quot;sigs.k8s.io/controller-runtime/pkg/client&quot; &quot;sigs.k8s.io/controller-runtime/pkg/webhook/admission&quot;)// +kubebuilder:webhook:admissionReviewVersions=v1,sideEffects=None,path=/validate-v1-svc,mutating=false,failurePolicy=fail,groups=&quot;&quot;,resources=services,verbs=create;update,versions=v1,name=vsvc.kb.io// KubeGameValidator validates Podstype KubeGameValidator struct &#123; Client client.Client decoder *admission.Decoder&#125;// Handle admits a pod if a specific annotation exists.func (v *KubeGameValidator) Handle(ctx context.Context, req admission.Request) admission.Response &#123; pod := &amp;corev1.Pod&#123;&#125; err := v.decoder.Decode(req, pod) if err != nil &#123; return admission.Errored(http.StatusBadRequest, err) &#125; key := &quot;example-mutating-admission-webhook&quot; anno, found := pod.Annotations[key] if !found &#123; return admission.Denied(fmt.Sprintf(&quot;missing annotation %s&quot;, key)) &#125; if anno != &quot;foo&quot; &#123; return admission.Denied(fmt.Sprintf(&quot;annotation %s did not have value %q&quot;, key, &quot;foo&quot;)) &#125; return admission.Allowed(&quot;&quot;)&#125;// KubeGameValidator implements admission.DecoderInjector.// A decoder will be automatically injected.// InjectDecoder injects the decoder.func (v *KubeGameValidator) InjectDecoder(d *admission.Decoder) error &#123; v.decoder = d return nil&#125; 注意：因为上述逻辑需要services权限，所以我们在控制器里需要添加如下内容 //+kubebuilder:rbac:groups=“”,resources=services,verbs=get;list;watch;create;update;patch;delete 用于生成 rbac manifests。 Register Your Handler 修改 main.go ，注册我们的 webhook handler 123456setupLog.Info(&quot;setting up webhook server&quot;)hookServer := mgr.GetWebhookServer()setupLog.Info(&quot;registering webhooks to the webhook server&quot;)hookServer.Register(&quot;/mutate-v1-svc&quot;, &amp;webhook.Admission&#123;Handler: &amp;controllers.KubeGameAnnotator&#123;Client: mgr.GetClient()&#125;&#125;)hookServer.Register(&quot;/validate-v1-svc&quot;, &amp;webhook.Admission&#123;Handler: &amp;controllers.KubeGameValidator&#123;Client: mgr.GetClient()&#125;&#125;) 提示： 这里注册的path（例如 validate-v1-sv）路径需要和 validatingwebhook.go 、mutatingwebhook.go 文件里的 CRD validation 匹配，不然 kustomize 生成出来的 webhook yaml 文件不对。 本地测试 make run 会报如下错误，是因为没有证书导致，需要配置证书，可以手动签发证书。 11.646924212701068e+09 ERROR setup problem running manager &#123;&quot;error&quot;: &quot;open /var/folders/67/375276sx6hv0nln1whwm5syh0000gq/T/k8s-webhook-server/serving-certs/tls.crt: no such file or directory&quot;&#125; 我本地指定证书目录： 123456789mgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options&#123; Scheme: scheme, MetricsBindAddress: metricsAddr, Port: 9443, HealthProbeBindAddress: probeAddr, LeaderElection: enableLeaderElection, LeaderElectionID: &quot;27e1b0af.blazehu.com&quot;, CertDir: &quot;./cert/&quot;, &#125;) 重新启动发现恢复正常 提示： run controller-gen rbac:roleName=manager-role crd webhook paths=./… output:crd:artifacts:config=config/crd/bases -w to see all available markers, or controller-gen rbac:roleName=manager-role crd webhook paths=./… output:crd:artifacts:config=config/crd/bases -h for usage 7. 部署至集群 7.1 部署 cert manager 建议使用 certmanager 为 webhook 服务器提供证书。其他解决方案也有效，只要它们将证书放在所需的位置。安装文档点这里 通过如下方式注入 caBundle : 123456789101112131415# This patch add annotation to admission webhook config and# the variables $(CERTIFICATE_NAMESPACE) and $(CERTIFICATE_NAME) will be substituted by kustomize.apiVersion: admissionregistration.k8s.io/v1kind: MutatingWebhookConfigurationmetadata: name: mutating-webhook-configuration annotations: cert-manager.io/inject-ca-from: $(CERTIFICATE_NAMESPACE)/$(CERTIFICATE_NAME)---apiVersion: admissionregistration.k8s.io/v1kind: ValidatingWebhookConfigurationmetadata: name: validating-webhook-configuration annotations: cert-manager.io/inject-ca-from: $(CERTIFICATE_NAMESPACE)/$(CERTIFICATE_NAME) 7.2 构建镜像 •镜像替换：default/manager_auth_proxy_patch.yaml 文件中的 gcr.io/kubebuilder/kube-rbac-proxy:v0.8.0 （网络慢） •Dockerfile 去掉 go mod download，直接使用本地 vendor 构建 （网络慢） •Dockerfile 去掉 COPY api/ api/， 因为没有创建 Resource •去掉 main.go 文件中配置的证书路径 12make docker-build IMG=xxxxmake docker-push IMG=xxxx 7.3 修改模版，然后部署 •修改 config/default/kustomization.yaml ， 将 webhook、certmanager 相关的注释去掉。 •修改 config/crd/kustomization.yaml ，将 webhook、certmanager 相关的注释去掉。 •修改 config/default/kustomization.yaml ， 将 crd 相关的给注释掉。 1make deploy IMG=xxxx 部署成功： 查看控制器日志： 7.4 测试 简单创建一个 service，webhook 会注入一个注解，并进行验证。下图可以看到成功注入。 控制日志： 说明：查看 MutatingWebhookConfiguration 配置可以看到 caBundle 被注入其中了。 8. 总结 总结下 webhook Admission 的优势： •webhook 可动态扩展 Admission 能力，满足自定义客户的需求。 •不需要重启 API Server，可通过创建 webhook configuration 热加载 webhook admission。 Reference documentation •https://kubernetes.io/zh/docs/reference/access-authn-authz/extensible-admission-controllers •https://kubernetes.io/zh/docs/tasks/tls/managing-tls-in-a-cluster/ •https://book.kubebuilder.io/reference/admission-webhook.html •https://github.com/kubernetes-sigs/controller-runtime/tree/master/examples/builtins","categories":[{"name":"K8s","slug":"K8s","permalink":"https://marklinglon.github.io/categories/K8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://marklinglon.github.io/tags/k8s/"}]},{"title":"Kubebuilder Webhook 开发之创建 TLS 证书","slug":"k8s/kubebuilder-webhook","date":"2020-06-20T16:00:00.000Z","updated":"2024-02-01T09:24:24.359Z","comments":true,"path":"2020/06/21/k8s/kubebuilder-webhook/","link":"","permalink":"https://marklinglon.github.io/2020/06/21/k8s/kubebuilder-webhook/","excerpt":"","text":"在编写一个准入 Webhook 服务时，需要配置相关证书，k8s 提供了 api 用于对用户自主创建的证书进行认证签发。以下部分演示为 Webhook 服务创建 TLS 证书。 创建 TLS 证书 创建你的证书 通过运行以下命令生成私钥: 123456789101112131415cat &lt;&lt;EOF | cfssl genkey - | cfssljson -bare server&#123; &quot;hosts&quot;: [ &quot;my-svc.my-namespace.svc.cluster.local&quot;, &quot;my-pod.my-namespace.pod.cluster.local&quot;, &quot;192.0.2.24&quot;, &quot;10.0.34.2&quot; ], &quot;CN&quot;: &quot;my-pod.my-namespace.pod.cluster.local&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;ecdsa&quot;, &quot;size&quot;: 256 &#125;&#125;EOF 此命令生成两个文件；它生成包含 PEM 编码 PKCS#10 证书请求的 server.csr， 以及 PEM 编码密钥的 server-key.pem，用于待生成的证书。 创建证书签名请求（CSR） 123456789101112cat &lt;&lt;EOF | kubectl apply -f -apiVersion: certificates.k8s.io/v1beta1kind: CertificateSigningRequestmetadata: name: examplespec: request: $(cat server.csr | base64 | tr -d &#x27;\\n&#x27;) usages: - digital signature - key encipherment - server authEOF 你能看到的输出类似于： 1certificatesigningrequest.certificates.k8s.io/example created Warning: certificates.k8s.io/v1beta1 CertificateSigningRequest is deprecated in v1.19+, unavailable in v1.22+; use certificates.k8s.io/v1 CertificateSigningRequest CSR 处于 Pending 状态。执行下面的命令你将可以看到： 1kubectl get csr 12NAME AGE SIGNERNAME REQUESTOR CONDITIONexample 17s kubernetes.io/legacy-unknown 100015926370-1650441195 Pending 批准证书签名请求（CSR） 1kubectl certificate approve example 1certificatesigningrequest.certificates.k8s.io/example approved 你现在应该能看到如下输出： 1kubectl get csr 12NAME AGE SIGNERNAME REQUESTOR CONDITIONexample 5m4s kubernetes.io/legacy-unknown 100015926370-1650441195 Approved,Issued 下载证书并使用它 1kubectl get csr example -o jsonpath=&#x27;&#123;.status.certificate&#125;&#x27; | base64 --decode &gt; server.crt 现在你可以将 server.crt 和 server-key.pem 作为你的服务的 https 认证了。 例如 kubebuilder 中使用 TLS 证书，将 server.crt 和 server-key.pem 放在 cert 目录中并修改名称为 tls.crt 和 tls.key，然后指定证书目录： 123456789mgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options&#123; Scheme: scheme, MetricsBindAddress: metricsAddr, Port: 9443, HealthProbeBindAddress: probeAddr, LeaderElection: enableLeaderElection, LeaderElectionID: &quot;27e1b0af.blazehu.com&quot;, CertDir: &quot;./cert/&quot;,&#125;) 从 v1beta1 迁移到 v1 上述例子使用 certificates.k8s.io/v1beta1 API 版本的 CertificateSigningRequest 不在 v1.22 版本中继续提供。官方迁移指南点这里。 我们可以使用 certificates.k8s.io/v1 API 版本，此 API 从 v1.19 版本开始可用。 •certificates.k8s.io/v1 中需要额外注意的变更： •对于请求证书的 API 客户端而言： •spec.signerName 现在变成必需字段（参阅 已知的 Kubernetes 签署者）， 并且通过 certificates.k8s.io/v1 API 不可以创建签署者为 kubernetes.io/legacy-unknown 的请求 •spec.usages 现在变成必需字段，其中不可以包含重复的字符串值， 并且只能包含已知的用法字符串 创建你的证书 通过运行以下命令生成私钥: 123456789101112131415cat &lt;&lt;EOF | cfssl genkey - | cfssljson -bare server&#123; &quot;hosts&quot;: [ &quot;my-svc.my-namespace.svc.cluster.local&quot;, &quot;my-pod.my-namespace.pod.cluster.local&quot;, &quot;192.0.2.24&quot;, &quot;10.0.34.2&quot; ], &quot;CN&quot;: &quot;my-pod.my-namespace.pod.cluster.local&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;ecdsa&quot;, &quot;size&quot;: 256 &#125;&#125;EOF 创建证书签名请求（CSR） 这里 csr signerName 不能是 kubernetes.io/legacy-unknown，演示我们随便指定一个为 example.com/serving，v1beta1 版本默认是 kubernetes.io/legacy-unknown。 12345678910111213cat &lt;&lt;EOF | kubectl apply -f -apiVersion: certificates.k8s.io/v1kind: CertificateSigningRequestmetadata: name: examplespec: request: $(cat server.csr | base64 | tr -d &#x27;\\n&#x27;) signerName: example.com/serving usages: - digital signature - key encipherment - server authEOF 批准证书签名请求（CSR） 1kubectl certificate approve example 1certificatesigningrequest.certificates.k8s.io/example approved 你现在应该能看到如下输出： 1kubectl get csr 12NAME AGE SIGNERNAME REQUESTOR CONDITIONexample 11s example.com/serving 100015926370-1650441195 Approved 这里可以看到证书请求已被批准，但是没有自动签名，正在等待请求的签名者对其签名。 签名证书签名请求（CSR） 我们扮演证书签署者的角色，颁发证书并将其上传到 API 服务器。 创建证书颁发机构 通过运行以下命令创建签名证书: 123456789cat &lt;&lt;EOF | cfssl gencert -initca - | cfssljson -bare ca&#123; &quot;CN&quot;: &quot;example.com/serving&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;&#125;EOF 这会产生一个证书颁发机构密钥文件（ca-key.pem）和证书（ca.pem）。 颁发证书 创建文件 server-signing-config.json 内容如下： 123456789101112131415&#123; &quot;signing&quot;: &#123; &quot;default&quot;: &#123; &quot;usages&quot;: [ &quot;digital signature&quot;, &quot;key encipherment&quot;, &quot;server auth&quot; ], &quot;expiry&quot;: &quot;876000h&quot;, &quot;ca_constraint&quot;: &#123; &quot;is_ca&quot;: false &#125; &#125; &#125;&#125; 使用 server-signing-config.json 签名配置、证书颁发机构密钥文件和证书来签署证书请求： 1234kubectl get csr example -o jsonpath=&#x27;&#123;.spec.request&#125;&#x27; | \\base64 --decode | \\cfssl sign -ca ca.pem -ca-key ca-key.pem -config server-signing-config.json - | \\cfssljson -bare ca-signed-server 这会生成一个签名的服务证书文件，ca-signed-server.pem。 上传签名证书 123kubectl get csr example -o json | \\jq &#x27;.status.certificate = &quot;&#x27;$(base64 ca-signed-server.pem | tr -d &#x27;\\n&#x27;)&#x27;&quot;&#x27; | \\kubectl replace --raw /apis/certificates.k8s.io/v1/certificatesigningrequests/example/status -f - 批准 CSR 并上传签名证书后，你现在应该能看到如下输出： 1kubectl get csr 12NAME AGE SIGNERNAME REQUESTOR CONDITIONexample 10m example.com/serving 100015926370-1650441195 Approved,Issued 这是你可以正常下载证书并使用它了。 参考文档 •https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/certificate-signing-requests/ •https://kubernetes.io/zh-cn/docs/tasks/tls/managing-tls-in-a-cluster/#configuring-your-cluster-to-provide-signing •https://kubernetes.io/zh-cn/docs/reference/using-api/deprecation-guide/","categories":[{"name":"K8s","slug":"K8s","permalink":"https://marklinglon.github.io/categories/K8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://marklinglon.github.io/tags/k8s/"}]},{"title":"Alertmanager","slug":"监控/alertmanager","date":"2018-05-20T16:00:00.000Z","updated":"2024-02-01T09:21:43.295Z","comments":true,"path":"2018/05/21/监控/alertmanager/","link":"","permalink":"https://marklinglon.github.io/2018/05/21/%E7%9B%91%E6%8E%A7/alertmanager/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748global: smtp_smarthost: &quot;&quot; smtp_from: &quot;&quot; smtp_auth_username: &quot;&quot; smtp_auth_password: &quot;&quot;route: route: group_by: [&quot;alertname&quot;,&quot;severity&quot;，&quot;pod&quot;,&quot;nodename&quot;] group_wait: 15s # 接收到告警后，多久开始发送 group_interval: 120s # 120s触发一次分组，如果有告警只告警一次，如果有新的告警，必须是120s之后才会触发告警，不会立即告警 repeat_interval: 21600s # 每个分组重复告警的时间间隔 receiver: devops routes: - receiver: devops group_wait: 10s match: severity: critical - receiver: devops group_wait: 10s match: severity: error - receiver: devops group_wait: 10s match: severity: warningreceivers:- name: &#x27;devops&#x27; webhook_configs: - url: http://alertmanager-wechat:8001 send_resolved: falseinhibit_rules: - source_match: severity: &#x27;critical&#x27; target_match: severity: &#x27;critical&#x27; equal: [&#x27;alertname&#x27;] - source_match: severity: &#x27;error&#x27; target_match: severity: &#x27;error&#x27; equal: [&#x27;alertname&#x27;] - source_match: severity: &#x27;warning&#x27; target_match: severity: &#x27;warning&#x27; equal: [&#x27;alertname&#x27;]","categories":[{"name":"监控","slug":"监控","permalink":"https://marklinglon.github.io/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://marklinglon.github.io/tags/k8s/"}]},{"title":"keypass激活码","slug":"工具/keypass","date":"2018-05-19T16:00:00.000Z","updated":"2024-02-01T09:23:37.001Z","comments":true,"path":"2018/05/20/工具/keypass/","link":"","permalink":"https://marklinglon.github.io/2018/05/20/%E5%B7%A5%E5%85%B7/keypass/","excerpt":"","text":"激活码 12345678910111234-5678-abcd-efgh-jklm-nopq-rstu-vwxy-8765LWL1-5S5S-RT2S-23HT-9UPM-939M-HFSS-5GNP-FHF2RZ9Y-2TPK-EMHH-HUNE-HPK5-KM93-3EGK-RET9-RTN5LRQP-FKTM-ESEE-9R32-EE9G-SE3M-GRKG-2MFF-HMM3I5QU-5SNF-EE9S-FNRU-UUTS-MGPE-RR2G-SN5S-9EP2DFOH-PN29-RFFG-GS93-5EGT-TKKP-NS5H-F52M-URU3MDOQ-UPKM-K59F-SR3N-S3RP-MPS9-9T2E-2RG3-TSS3BOOU-NT3S-UR3R-U95G-M3GK-ERHM-3HG2-9SKG-S3N5M7DM-KMST-K22P-3229-9MG3-GK9S-PFK5-KMKU-SS55WKU4-H3PG-URNK-HS3S-PHK9-5R2N-MMKE-MTKR-HKE3ZJHL-REGF-HTUS-MH2R-PNSE-KHK5-5KM9-UP9K-NTG9","categories":[{"name":"工具","slug":"工具","permalink":"https://marklinglon.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"keypass","slug":"keypass","permalink":"https://marklinglon.github.io/tags/keypass/"}]}],"categories":[{"name":"算法","slug":"算法","permalink":"https://marklinglon.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"mianshiti","slug":"mianshiti","permalink":"https://marklinglon.github.io/categories/mianshiti/"},{"name":"工具","slug":"工具","permalink":"https://marklinglon.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"name":"K8s","slug":"K8s","permalink":"https://marklinglon.github.io/categories/K8s/"},{"name":"Docker","slug":"Docker","permalink":"https://marklinglon.github.io/categories/Docker/"},{"name":"CICD","slug":"CICD","permalink":"https://marklinglon.github.io/categories/CICD/"},{"name":"中间件","slug":"中间件","permalink":"https://marklinglon.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"语言","slug":"语言","permalink":"https://marklinglon.github.io/categories/%E8%AF%AD%E8%A8%80/"},{"name":"监控","slug":"监控","permalink":"https://marklinglon.github.io/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"K个一组反转列表","slug":"K个一组反转列表","permalink":"https://marklinglon.github.io/tags/K%E4%B8%AA%E4%B8%80%E7%BB%84%E5%8F%8D%E8%BD%AC%E5%88%97%E8%A1%A8/"},{"name":"最小数","slug":"最小数","permalink":"https://marklinglon.github.io/tags/%E6%9C%80%E5%B0%8F%E6%95%B0/"},{"name":"LRU缓存机制","slug":"LRU缓存机制","permalink":"https://marklinglon.github.io/tags/LRU%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/"},{"name":"旋转排序数组","slug":"旋转排序数组","permalink":"https://marklinglon.github.io/tags/%E6%97%8B%E8%BD%AC%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84/"},{"name":"栈 队列","slug":"栈-队列","permalink":"https://marklinglon.github.io/tags/%E6%A0%88-%E9%98%9F%E5%88%97/"},{"name":"不含AAA或BBB的字符串","slug":"不含AAA或BBB的字符串","permalink":"https://marklinglon.github.io/tags/%E4%B8%8D%E5%90%ABAAA%E6%88%96BBB%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"二叉树的最近公共祖先","slug":"二叉树的最近公共祖先","permalink":"https://marklinglon.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E8%BF%91%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88/"},{"name":"合并区间","slug":"合并区间","permalink":"https://marklinglon.github.io/tags/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/"},{"name":"四数组相加II","slug":"四数组相加II","permalink":"https://marklinglon.github.io/tags/%E5%9B%9B%E6%95%B0%E7%BB%84%E7%9B%B8%E5%8A%A0II/"},{"name":"子集","slug":"子集","permalink":"https://marklinglon.github.io/tags/%E5%AD%90%E9%9B%86/"},{"name":"字符串解码","slug":"字符串解码","permalink":"https://marklinglon.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%A7%A3%E7%A0%81/"},{"name":"二叉树的锯齿型层次遍历","slug":"二叉树的锯齿型层次遍历","permalink":"https://marklinglon.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%94%AF%E9%BD%BF%E5%9E%8B%E5%B1%82%E6%AC%A1%E9%81%8D%E5%8E%86/"},{"name":"数组中的第K个最大元素","slug":"数组中的第K个最大元素","permalink":"https://marklinglon.github.io/tags/%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E7%AC%ACK%E4%B8%AA%E6%9C%80%E5%A4%A7%E5%85%83%E7%B4%A0/"},{"name":"对称二叉树","slug":"对称二叉树","permalink":"https://marklinglon.github.io/tags/%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"求和","slug":"求和","permalink":"https://marklinglon.github.io/tags/%E6%B1%82%E5%92%8C/"},{"name":"整数反转","slug":"整数反转","permalink":"https://marklinglon.github.io/tags/%E6%95%B4%E6%95%B0%E5%8F%8D%E8%BD%AC/"},{"name":"根到叶子结点的数字之和","slug":"根到叶子结点的数字之和","permalink":"https://marklinglon.github.io/tags/%E6%A0%B9%E5%88%B0%E5%8F%B6%E5%AD%90%E7%BB%93%E7%82%B9%E7%9A%84%E6%95%B0%E5%AD%97%E4%B9%8B%E5%92%8C/"},{"name":"数组 组合","slug":"数组-组合","permalink":"https://marklinglon.github.io/tags/%E6%95%B0%E7%BB%84-%E7%BB%84%E5%90%88/"},{"name":"最大正方形","slug":"最大正方形","permalink":"https://marklinglon.github.io/tags/%E6%9C%80%E5%A4%A7%E6%AD%A3%E6%96%B9%E5%BD%A2/"},{"name":"路径总和","slug":"路径总和","permalink":"https://marklinglon.github.io/tags/%E8%B7%AF%E5%BE%84%E6%80%BB%E5%92%8C/"},{"name":"罗马数字转整数","slug":"罗马数字转整数","permalink":"https://marklinglon.github.io/tags/%E7%BD%97%E9%A9%AC%E6%95%B0%E5%AD%97%E8%BD%AC%E6%95%B4%E6%95%B0/"},{"name":"redis","slug":"redis","permalink":"https://marklinglon.github.io/tags/redis/"},{"name":"jumpserer","slug":"jumpserer","permalink":"https://marklinglon.github.io/tags/jumpserer/"},{"name":"gpt","slug":"gpt","permalink":"https://marklinglon.github.io/tags/gpt/"},{"name":"k8s","slug":"k8s","permalink":"https://marklinglon.github.io/tags/k8s/"},{"name":"docker","slug":"docker","permalink":"https://marklinglon.github.io/tags/docker/"},{"name":"gitops","slug":"gitops","permalink":"https://marklinglon.github.io/tags/gitops/"},{"name":"elastic","slug":"elastic","permalink":"https://marklinglon.github.io/tags/elastic/"},{"name":"hexo","slug":"hexo","permalink":"https://marklinglon.github.io/tags/hexo/"},{"name":"java","slug":"java","permalink":"https://marklinglon.github.io/tags/java/"},{"name":"keypass","slug":"keypass","permalink":"https://marklinglon.github.io/tags/keypass/"}]}